{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bseMhgZ6sqBm",
        "outputId": "0d903e37-c0f0-48b2-bfc1-9b8992e2a808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import copy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import random\n",
        "import optuna\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Data Preparation\n",
        "\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Filter rows where 'Output' length is <=200\n",
        "    df = df[df['Output'].str.len() <= 200]\n",
        "\n",
        "    # Get the count of such rows\n",
        "    count_filtered = len(df)\n",
        "\n",
        "\n",
        "    if count_filtered > 100:\n",
        "        df = df.sample(n=100, random_state=42)\n",
        "\n",
        "    inputs = df['Input'].tolist()\n",
        "    outputs = df['Output'].tolist()\n",
        "\n",
        "    return inputs, outputs\n",
        "\n",
        "# Tokenization and Vocabulary\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.char2idx = {}\n",
        "        self.idx2char = {}\n",
        "        self.pad_token = 0\n",
        "        self.sos_token = 1\n",
        "        self.eos_token = 2\n",
        "        self.unk_token = 3\n",
        "        self._build_vocab()\n",
        "\n",
        "    def _build_vocab(self):\n",
        "        special_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
        "        all_chars = list(string.printable)\n",
        "\n",
        "        self.char2idx = {token: idx for idx, token in enumerate(special_tokens)}\n",
        "        self.char2idx.update({char: idx+len(special_tokens) for idx, char in enumerate(all_chars)})\n",
        "        self.idx2char = {idx: char for char, idx in self.char2idx.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.char2idx)\n",
        "\n",
        "    def encode(self, text):\n",
        "        return [self.char2idx.get(char, self.unk_token) for char in text]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        return ''.join([self.idx2char.get(idx, '<UNK>') for idx in indices if idx not in {self.pad_token, self.sos_token, self.eos_token}])\n",
        "\n",
        "# Dataset Class\n",
        "class CipherDataset(data.Dataset):\n",
        "    def __init__(self, inputs, outputs, vocab, max_length):\n",
        "        self.inputs = inputs\n",
        "        self.outputs = outputs\n",
        "        self.vocab = vocab\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = str(self.inputs[idx])\n",
        "        output_text = str(self.outputs[idx])\n",
        "\n",
        "        input_encoded = [self.vocab.sos_token] + self.vocab.encode(input_text) + [self.vocab.eos_token]\n",
        "        output_encoded = [self.vocab.sos_token] + self.vocab.encode(output_text) + [self.vocab.eos_token]\n",
        "\n",
        "        input_padded = input_encoded + [self.vocab.pad_token] * (self.max_length - len(input_encoded))\n",
        "        output_padded = output_encoded + [self.vocab.pad_token] * (self.max_length - len(output_encoded))\n",
        "\n",
        "        input_padded = input_padded[:self.max_length]\n",
        "        output_padded = output_padded[:self.max_length]\n",
        "\n",
        "        return torch.tensor(input_padded), torch.tensor(output_padded)\n",
        "\n",
        "# Transformer Model Components\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_pad_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_len = tgt.size(1)\n",
        "        tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=device)).bool()\n",
        "        tgt_mask = tgt_pad_mask & tgt_sub_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        output = self.fc(dec_output)\n",
        "        return output\n",
        "\n",
        "# Training and Evaluation Functions\n",
        "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt in tqdm(train_loader, desc=\"Training\"):\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt[:, :-1])\n",
        "        loss = criterion(output.contiguous().view(-1, output.size(-1)),\n",
        "                        tgt[:, 1:].contiguous().view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            loss = criterion(output.contiguous().view(-1, output.size(-1)),\n",
        "                            tgt[:, 1:].contiguous().view(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "def calculate_accuracy(model, data_loader, vocab, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in data_loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            predictions = output.argmax(dim=-1)\n",
        "            correct += ((predictions == tgt[:, 1:]) & (tgt[:, 1:] != vocab.pad_token)).sum().item()\n",
        "            total += (tgt[:, 1:] != vocab.pad_token).sum().item()\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs, patience=3):\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                break\n",
        "    return best_val_loss  # Return the best validation loss from this training run\n",
        "\n",
        "# Global variables to track best model across all trials\n",
        "best_overall_model = None\n",
        "best_overall_loss = float('inf')\n",
        "best_config = None\n",
        "\n",
        "# Hyperparameter Optimization with Optuna\n",
        "def objective(trial):\n",
        "    global best_overall_model, best_overall_loss, best_config\n",
        "\n",
        "    config = {\n",
        "        \"d_model\": trial.suggest_categorical(\"d_model\", [128, 256, 512, 1024]),\n",
        "        \"num_heads\": trial.suggest_categorical(\"num_heads\", [4, 8, 16, 32, 64]),\n",
        "        \"num_layers\": trial.suggest_categorical(\"num_layers\", [8, 10, 12, 24, 48]),\n",
        "        \"d_ff\": trial.suggest_categorical(\"d_ff\", [256, 512, 1024]),\n",
        "        \"dropout\": trial.suggest_float(\"dropout\", 0.05, 0.4),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
        "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [16]),\n",
        "    }\n",
        "\n",
        "    # Create data loaders with current batch size\n",
        "    train_loader = data.DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = data.DataLoader(val_dataset, batch_size=config[\"batch_size\"])\n",
        "\n",
        "    # Initialize model\n",
        "    model = Transformer(\n",
        "        src_vocab_size=len(vocab),\n",
        "        tgt_vocab_size=len(vocab),\n",
        "        d_model=config[\"d_model\"],\n",
        "        num_heads=config[\"num_heads\"],\n",
        "        num_layers=config[\"num_layers\"],\n",
        "        d_ff=config[\"d_ff\"],\n",
        "        max_seq_length=max_length,\n",
        "        dropout=config[\"dropout\"]\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=vocab.pad_token)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
        "\n",
        "    # Train and get best validation loss for this configuration\n",
        "    current_val_loss = train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=5)\n",
        "\n",
        "    # Update overall best model if this one is better\n",
        "    if current_val_loss < best_overall_loss:\n",
        "        best_overall_loss = current_val_loss\n",
        "        best_overall_model = copy.deepcopy(model.state_dict())\n",
        "        best_config = config\n",
        "        torch.save(best_overall_model, '/content/drive/MyDrive/best_caesar_5.pth')\n",
        "        print(f\"New best model found! Val Loss: {current_val_loss:.4f}\")\n",
        "        print(f\"Config: {config}\")\n",
        "\n",
        "    return current_val_loss\n",
        "\n",
        "# Decryption Function\n",
        "def decrypt_text(model, text, vocab, max_length, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded = [vocab.sos_token] + vocab.encode(str(text)) + [vocab.eos_token]\n",
        "        encoded = encoded + [vocab.pad_token] * (max_length - len(encoded))\n",
        "        encoded = torch.tensor(encoded[:max_length]).unsqueeze(0).to(device)\n",
        "\n",
        "        target = torch.tensor([[vocab.sos_token]]).to(device)\n",
        "\n",
        "        for _ in range(max_length - 1):\n",
        "            output = model(encoded, target)\n",
        "            next_token = output.argmax(2)[:, -1].item()\n",
        "            if next_token == vocab.eos_token:\n",
        "                break\n",
        "            target = torch.cat([target, torch.tensor([[next_token]]).to(device)], dim=1)\n",
        "\n",
        "        decrypted = vocab.decode(target[0].cpu().numpy())\n",
        "        return decrypted\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and prepare data\n",
        "    inputs, outputs = load_data('/content/training_newshift_1.csv')\n",
        "    vocab = Vocabulary()\n",
        "    max_length = 256\n",
        "\n",
        "    # Split data\n",
        "    train_inputs, val_inputs, train_outputs, val_outputs = train_test_split(\n",
        "        inputs, outputs, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CipherDataset(train_inputs, train_outputs, vocab, max_length)\n",
        "    val_dataset = CipherDataset(val_inputs, val_outputs, vocab, max_length)\n",
        "\n",
        "    # Run hyperparameter optimization\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=20)  # 20 trials or 1 hour\n",
        "\n",
        "    print(\"\\nBest trial:\")\n",
        "    trial = study.best_trial\n",
        "    print(f\"  Validation Loss: {trial.value:.4f}\")\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(f\"    {key}: {value}\")\n",
        "\n",
        "    # Load the best model found during the search\n",
        "    final_model = Transformer(\n",
        "        src_vocab_size=len(vocab),\n",
        "        tgt_vocab_size=len(vocab),\n",
        "        d_model=best_config[\"d_model\"],\n",
        "        num_heads=best_config[\"num_heads\"],\n",
        "        num_layers=best_config[\"num_layers\"],\n",
        "        d_ff=best_config[\"d_ff\"],\n",
        "        max_seq_length=max_length,\n",
        "        dropout=best_config[\"dropout\"]\n",
        "    ).to(device)\n",
        "    final_model.load_state_dict(torch.load('/content/drive/MyDrive/best_caesar_5.pth'))\n",
        "\n",
        "    # Evaluate on full datasets\n",
        "    full_train_loader = data.DataLoader(train_dataset, batch_size=best_config[\"batch_size\"], shuffle=False)\n",
        "    full_val_loader = data.DataLoader(val_dataset, batch_size=best_config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=vocab.pad_token)\n",
        "\n",
        "    train_loss = evaluate(final_model, full_train_loader, criterion, device)\n",
        "    val_loss = evaluate(final_model, full_val_loader, criterion, device)\n",
        "\n",
        "    train_acc = calculate_accuracy(final_model, full_train_loader, vocab, device)\n",
        "    val_acc = calculate_accuracy(final_model, full_val_loader, vocab, device)\n",
        "\n",
        "    print(\"\\nFinal Evaluation:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"Train Accuracy: {train_acc:.4f} | Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Test decryption\n",
        "    test_cases = [\n",
        "        (\"Please decrypt the following using Caesar cipher: gfbs\", \"fear\"),\n",
        "        (\"Please decrypt the following using Caesar cipher: dpnqvufs\", \"computer\"),\n",
        "        (\"Please decrypt the following using Caesar cipher:xibu\", \"what\")\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTest Decryptions:\")\n",
        "    for encrypted, expected in test_cases:\n",
        "        decrypted = decrypt_text(final_model, encrypted, vocab, max_length, device)\n",
        "        print(f\"Input: '{encrypted}' | Output: '{decrypted}' | Expected: '{expected}' | {'✓' if decrypted == expected else '✗'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYT2CjVyusf1",
        "outputId": "98bba61b-2799-46a6-c72f-b402727071a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 08:48:56,340] A new study created in memory with name: no-name-5957f2a6-3cce-4b38-acca-f9be97f15ea3\n",
            "Training: 100%|██████████| 5/5 [01:16<00:00, 15.27s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.7517 | Val Loss: 3.1860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:03<00:00, 12.67s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.1816 | Val Loss: 3.1286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:13<00:00, 14.62s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.1379 | Val Loss: 3.1401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:00<00:00, 12.15s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.1458 | Val Loss: 3.1405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:01<00:00, 12.26s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1323 | Val Loss: 3.1354\n",
            "Early stopping triggered!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 08:55:00,714] Trial 0 finished with value: 3.128631591796875 and parameters: {'d_model': 256, 'num_heads': 16, 'num_layers': 24, 'd_ff': 256, 'dropout': 0.29785288366674223, 'learning_rate': 0.0026370692885369224, 'batch_size': 16}. Best is trial 0 with value: 3.128631591796875.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model found! Val Loss: 3.1286\n",
            "Config: {'d_model': 256, 'num_heads': 16, 'num_layers': 24, 'd_ff': 256, 'dropout': 0.29785288366674223, 'learning_rate': 0.0026370692885369224, 'batch_size': 16}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:09<00:00,  1.91s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.9285 | Val Loss: 3.3248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:10<00:00,  2.02s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.1972 | Val Loss: 3.1480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:09<00:00,  1.91s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.1445 | Val Loss: 3.1273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:09<00:00,  1.93s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.1142 | Val Loss: 3.1335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:09<00:00,  1.93s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n",
            "[I 2025-05-07 08:55:53,559] Trial 1 finished with value: 3.1165547370910645 and parameters: {'d_model': 256, 'num_heads': 4, 'num_layers': 8, 'd_ff': 256, 'dropout': 0.07477403407988911, 'learning_rate': 0.0017429029205439238, 'batch_size': 16}. Best is trial 1 with value: 3.1165547370910645.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1206 | Val Loss: 3.1166\n",
            "New best model found! Val Loss: 3.1166\n",
            "Config: {'d_model': 256, 'num_heads': 4, 'num_layers': 8, 'd_ff': 256, 'dropout': 0.07477403407988911, 'learning_rate': 0.0017429029205439238, 'batch_size': 16}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:30<00:00, 18.11s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:09<00:00,  4.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.9050 | Val Loss: 3.5373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:27<00:00, 17.48s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:09<00:00,  4.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.4796 | Val Loss: 3.4229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:28<00:00, 17.62s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:09<00:00,  4.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.3608 | Val Loss: 3.2937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:28<00:00, 17.62s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:09<00:00,  4.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.2017 | Val Loss: 3.1256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:27<00:00, 17.42s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:09<00:00,  4.69s/it]\n",
            "[I 2025-05-07 09:04:01,920] Trial 2 finished with value: 3.0405783653259277 and parameters: {'d_model': 128, 'num_heads': 64, 'num_layers': 12, 'd_ff': 512, 'dropout': 0.07716354365620323, 'learning_rate': 0.0003781438079385575, 'batch_size': 16}. Best is trial 2 with value: 3.0405783653259277.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 2.9665 | Val Loss: 3.0406\n",
            "New best model found! Val Loss: 3.0406\n",
            "Config: {'d_model': 128, 'num_heads': 64, 'num_layers': 12, 'd_ff': 512, 'dropout': 0.07716354365620323, 'learning_rate': 0.0003781438079385575, 'batch_size': 16}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:15<00:00, 15.07s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 24.2899 | Val Loss: 59.2690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:13<00:00, 14.79s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 59.1122 | Val Loss: 54.8076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:13<00:00, 14.72s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 46.6533 | Val Loss: 50.7513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:14<00:00, 14.98s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 38.8452 | Val Loss: 51.7273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:14<00:00, 14.84s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]\n",
            "[I 2025-05-07 09:10:45,455] Trial 3 finished with value: 13.262210845947266 and parameters: {'d_model': 1024, 'num_heads': 16, 'num_layers': 8, 'd_ff': 256, 'dropout': 0.2883942069728467, 'learning_rate': 0.05136395368071393, 'batch_size': 16}. Best is trial 2 with value: 3.0405783653259277.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 24.9412 | Val Loss: 13.2622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:19<00:00,  3.92s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.9276 | Val Loss: 3.3066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:20<00:00,  4.01s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.2293 | Val Loss: 3.1465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:19<00:00,  3.93s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.1291 | Val Loss: 3.1257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:20<00:00,  4.16s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.1212 | Val Loss: 3.1209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:19<00:00,  3.94s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\n",
            "[I 2025-05-07 09:12:35,586] Trial 4 finished with value: 3.1200751066207886 and parameters: {'d_model': 128, 'num_heads': 8, 'num_layers': 24, 'd_ff': 256, 'dropout': 0.24524513052117597, 'learning_rate': 0.002112101483378704, 'batch_size': 16}. Best is trial 2 with value: 3.0405783653259277.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1085 | Val Loss: 3.1201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:38<00:00,  7.72s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.8553 | Val Loss: 3.3687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:48<00:00,  9.60s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.3213 | Val Loss: 3.2535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:04<00:00, 12.89s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.1053 | Val Loss: 3.0334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:38<00:00,  7.76s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 2.8195 | Val Loss: 2.8939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:38<00:00,  7.66s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 2.6327 | Val Loss: 2.7840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 09:16:43,101] Trial 5 finished with value: 2.784000277519226 and parameters: {'d_model': 256, 'num_heads': 32, 'num_layers': 8, 'd_ff': 1024, 'dropout': 0.1323467788673861, 'learning_rate': 0.00023489726805644886, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model found! Val Loss: 2.7840\n",
            "Config: {'d_model': 256, 'num_heads': 32, 'num_layers': 8, 'd_ff': 1024, 'dropout': 0.1323467788673861, 'learning_rate': 0.00023489726805644886, 'batch_size': 16}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:35<00:00, 19.10s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:07<00:00,  3.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 8.9425 | Val Loss: 16.4531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:30<00:00, 18.07s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 11.5588 | Val Loss: 12.7127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:31<00:00, 18.25s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 10.8212 | Val Loss: 12.3122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:31<00:00, 18.28s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 7.9857 | Val Loss: 7.7860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:33<00:00, 18.67s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:12<00:00,  6.06s/it]\n",
            "[I 2025-05-07 09:25:05,471] Trial 6 finished with value: 4.8192222118377686 and parameters: {'d_model': 1024, 'num_heads': 32, 'num_layers': 8, 'd_ff': 256, 'dropout': 0.33022175067096715, 'learning_rate': 0.01800062664829373, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 5.7901 | Val Loss: 4.8192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:31<00:00,  6.21s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 4.4396 | Val Loss: 4.0612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:28<00:00,  5.64s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.9230 | Val Loss: 3.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:27<00:00,  5.59s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.6901 | Val Loss: 3.6184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:27<00:00,  5.55s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.5623 | Val Loss: 3.5220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:27<00:00,  5.55s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]\n",
            "[I 2025-05-07 09:27:39,398] Trial 7 finished with value: 3.4576538801193237 and parameters: {'d_model': 256, 'num_heads': 16, 'num_layers': 10, 'd_ff': 1024, 'dropout': 0.08576350453652332, 'learning_rate': 1.0440106671227166e-05, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.4723 | Val Loss: 3.4577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:47<00:00, 57.51s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:37<00:00, 18.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 22.8031 | Val Loss: 61.4602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:26<00:00, 53.37s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:22<00:00, 11.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 54.1001 | Val Loss: 35.4148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:25<00:00, 53.12s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:22<00:00, 11.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 40.6571 | Val Loss: 45.8305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:23<00:00, 52.65s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:22<00:00, 11.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 42.5359 | Val Loss: 41.8926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:23<00:00, 52.75s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:22<00:00, 11.13s/it]\n",
            "[I 2025-05-07 09:52:16,491] Trial 8 finished with value: 20.31082820892334 and parameters: {'d_model': 1024, 'num_heads': 16, 'num_layers': 24, 'd_ff': 1024, 'dropout': 0.14245868486854812, 'learning_rate': 0.0506689470459807, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 29.8232 | Val Loss: 20.3108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:27<00:00,  5.56s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.6665 | Val Loss: 3.2551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:27<00:00,  5.46s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.1838 | Val Loss: 3.1833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:27<00:00,  5.51s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.1555 | Val Loss: 3.1381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:31<00:00,  6.39s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.1434 | Val Loss: 3.1589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:27<00:00,  5.58s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1165 | Val Loss: 3.1400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 09:54:53,090] Trial 9 finished with value: 3.1381282806396484 and parameters: {'d_model': 128, 'num_heads': 8, 'num_layers': 24, 'd_ff': 1024, 'dropout': 0.3096051439138539, 'learning_rate': 0.007355223630510876, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n",
            "Training: 100%|██████████| 5/5 [05:06<00:00, 61.32s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:26<00:00, 13.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.9438 | Val Loss: 3.3875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:46<00:00, 57.24s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:21<00:00, 10.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.2682 | Val Loss: 3.2215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:41<00:00, 56.22s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:21<00:00, 10.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.1916 | Val Loss: 3.1491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:43<00:00, 56.68s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:21<00:00, 10.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.1725 | Val Loss: 3.1712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:50<00:00, 58.04s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:21<00:00, 10.64s/it]\n",
            "[I 2025-05-07 10:20:53,388] Trial 10 finished with value: 3.1366809606552124 and parameters: {'d_model': 512, 'num_heads': 32, 'num_layers': 48, 'd_ff': 512, 'dropout': 0.17387476284353573, 'learning_rate': 0.00013098820652767115, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1482 | Val Loss: 3.1367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:48<00:00,  9.78s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.9881 | Val Loss: 3.6175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:48<00:00,  9.68s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.5750 | Val Loss: 3.4903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:47<00:00,  9.58s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.4655 | Val Loss: 3.4067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:47<00:00,  9.54s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.3738 | Val Loss: 3.3255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:47<00:00,  9.44s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.61s/it]\n",
            "[I 2025-05-07 10:25:20,451] Trial 11 finished with value: 3.2394295930862427 and parameters: {'d_model': 128, 'num_heads': 64, 'num_layers': 12, 'd_ff': 512, 'dropout': 0.14604254399345204, 'learning_rate': 0.0002843364177049067, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.2933 | Val Loss: 3.2394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:33<00:00, 18.62s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:07<00:00,  3.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.9864 | Val Loss: 3.3347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:17<00:00, 15.60s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:07<00:00,  3.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.2617 | Val Loss: 3.2289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:17<00:00, 15.48s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:07<00:00,  3.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.1817 | Val Loss: 3.1551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:27<00:00, 17.58s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:07<00:00,  3.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.1358 | Val Loss: 3.1662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:18<00:00, 15.67s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:07<00:00,  3.89s/it]\n",
            "[I 2025-05-07 10:32:53,542] Trial 12 finished with value: 3.1335554122924805 and parameters: {'d_model': 512, 'num_heads': 64, 'num_layers': 12, 'd_ff': 512, 'dropout': 0.05247997610514199, 'learning_rate': 0.00015824032268813015, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1328 | Val Loss: 3.1336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [01:02<00:00, 12.49s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 4.1221 | Val Loss: 3.5186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:59<00:00, 11.89s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.5104 | Val Loss: 3.3676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:59<00:00, 11.80s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.3991 | Val Loss: 3.3098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:58<00:00, 11.67s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.3514 | Val Loss: 3.2757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:58<00:00, 11.61s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]\n",
            "[I 2025-05-07 10:38:22,272] Trial 13 finished with value: 3.2346073389053345 and parameters: {'d_model': 256, 'num_heads': 64, 'num_layers': 12, 'd_ff': 1024, 'dropout': 0.1989375857863354, 'learning_rate': 3.597719751062505e-05, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.2975 | Val Loss: 3.2346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:22<00:00,  4.51s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 4.0489 | Val Loss: 3.5945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:26<00:00,  5.26s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.5354 | Val Loss: 3.4152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:22<00:00,  4.57s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.2963 | Val Loss: 3.1742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:22<00:00,  4.58s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.0559 | Val Loss: 3.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:26<00:00,  5.39s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]\n",
            "[I 2025-05-07 10:40:37,244] Trial 14 finished with value: 2.8626458644866943 and parameters: {'d_model': 128, 'num_heads': 32, 'num_layers': 10, 'd_ff': 512, 'dropout': 0.1027490625168909, 'learning_rate': 0.00040449135367057486, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 2.8466 | Val Loss: 2.8626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:26<00:00,  5.31s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.9852 | Val Loss: 3.5351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:22<00:00,  4.51s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.4886 | Val Loss: 3.3494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:22<00:00,  4.55s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.3207 | Val Loss: 3.2393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:22<00:00,  4.52s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.2212 | Val Loss: 3.1692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:22<00:00,  4.44s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]\n",
            "[I 2025-05-07 10:42:46,692] Trial 15 finished with value: 3.145572781562805 and parameters: {'d_model': 128, 'num_heads': 32, 'num_layers': 10, 'd_ff': 512, 'dropout': 0.3763254324852493, 'learning_rate': 0.0006492165720201931, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1771 | Val Loss: 3.1456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:39<00:00,  7.83s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 4.0555 | Val Loss: 3.5083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:32<00:00,  6.46s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.4473 | Val Loss: 3.3467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:32<00:00,  6.43s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.3255 | Val Loss: 3.2700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:32<00:00,  6.44s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.2555 | Val Loss: 3.1976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:32<00:00,  6.41s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]\n",
            "[I 2025-05-07 10:45:50,387] Trial 16 finished with value: 3.0885809659957886 and parameters: {'d_model': 256, 'num_heads': 32, 'num_layers': 10, 'd_ff': 1024, 'dropout': 0.12546131819846199, 'learning_rate': 5.0675551279102695e-05, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1515 | Val Loss: 3.0886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:34<00:00, 54.88s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:20<00:00, 10.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.9578 | Val Loss: 3.3969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:24<00:00, 52.93s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:21<00:00, 10.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.3173 | Val Loss: 3.2668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:22<00:00, 52.53s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:21<00:00, 10.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.2394 | Val Loss: 3.1897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:15<00:00, 51.20s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:20<00:00, 10.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.1974 | Val Loss: 3.1896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [04:27<00:00, 53.43s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:21<00:00, 10.55s/it]\n",
            "[I 2025-05-07 11:09:40,997] Trial 17 finished with value: 3.1657798290252686 and parameters: {'d_model': 512, 'num_heads': 32, 'num_layers': 48, 'd_ff': 512, 'dropout': 0.23666788716478213, 'learning_rate': 7.31970107215787e-05, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1790 | Val Loss: 3.1658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:07<00:00,  1.53s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 4.7000 | Val Loss: 4.4264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:07<00:00,  1.45s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 4.3099 | Val Loss: 4.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:07<00:00,  1.51s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 4.0780 | Val Loss: 3.9634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:07<00:00,  1.53s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.9301 | Val Loss: 3.8492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  3.12it/s]\n",
            "[I 2025-05-07 11:10:21,986] Trial 18 finished with value: 3.7663902044296265 and parameters: {'d_model': 128, 'num_heads': 4, 'num_layers': 8, 'd_ff': 1024, 'dropout': 0.11165614594826444, 'learning_rate': 1.4463366864297413e-05, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.8328 | Val Loss: 3.7664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:28<00:00,  5.76s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 3.8924 | Val Loss: 3.3864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:29<00:00,  5.97s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:05<00:00,  2.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "Train Loss: 3.2570 | Val Loss: 3.1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:36<00:00,  7.27s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "Train Loss: 3.1536 | Val Loss: 3.1337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:29<00:00,  5.80s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "Train Loss: 3.1365 | Val Loss: 3.1390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [00:29<00:00,  5.92s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]\n",
            "[I 2025-05-07 11:13:12,344] Trial 19 finished with value: 3.1151251792907715 and parameters: {'d_model': 256, 'num_heads': 32, 'num_layers': 10, 'd_ff': 512, 'dropout': 0.19053928707810275, 'learning_rate': 0.0008111895286008717, 'batch_size': 16}. Best is trial 5 with value: 2.784000277519226.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "Train Loss: 3.1216 | Val Loss: 3.1151\n",
            "\n",
            "Best trial:\n",
            "  Validation Loss: 2.7840\n",
            "  Params: \n",
            "    d_model: 256\n",
            "    num_heads: 32\n",
            "    num_layers: 8\n",
            "    d_ff: 1024\n",
            "    dropout: 0.1323467788673861\n",
            "    learning_rate: 0.00023489726805644886\n",
            "    batch_size: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 5/5 [00:10<00:00,  2.07s/it]\n",
            "Evaluating: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Evaluation:\n",
            "Train Loss: 2.5061 | Val Loss: 2.7840\n",
            "Train Accuracy: 0.2925 | Val Accuracy: 0.2179\n",
            "\n",
            "Test Decryptions:\n",
            "Input: 'Please decrypt the following using Caesar cipher: gfbs' | Output: 'Tom an the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the ' | Expected: 'fear' | ✗\n",
            "Input: 'Please decrypt the following using Caesar cipher: dpnqvufs' | Output: 'Tom an the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the ' | Expected: 'computer' | ✗\n",
            "Input: 'Please decrypt the following using Caesar cipher:xibu' | Output: 'Tom an the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the ' | Expected: 'what' | ✗\n"
          ]
        }
      ]
    }
  ]
}