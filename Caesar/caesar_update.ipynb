{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q6FrFXlnNxMs",
        "outputId": "1e1431b4-f954-4243-a9dc-054408b49e78"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Results:\n",
            "Train Loss: 1.1808 | Train Acc: 0.9732\n",
            "Val Loss: 0.0934 | Val Acc: 0.9724\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:21<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Results:\n",
            "Train Loss: 0.1089 | Train Acc: 0.9903\n",
            "Val Loss: 0.0329 | Val Acc: 0.9899\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 Results:\n",
            "Train Loss: 0.0570 | Train Acc: 0.9947\n",
            "Val Loss: 0.0181 | Val Acc: 0.9944\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Results:\n",
            "Train Loss: 0.0381 | Train Acc: 0.9964\n",
            "Val Loss: 0.0120 | Val Acc: 0.9963\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:21<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 Results:\n",
            "Train Loss: 0.0277 | Train Acc: 0.9973\n",
            "Val Loss: 0.0093 | Val Acc: 0.9972\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:21<00:00,  1.11s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 Results:\n",
            "Train Loss: 0.0219 | Train Acc: 0.9977\n",
            "Val Loss: 0.0077 | Val Acc: 0.9976\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:21<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7 Results:\n",
            "Train Loss: 0.0181 | Train Acc: 0.9979\n",
            "Val Loss: 0.0069 | Val Acc: 0.9979\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:21<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8 Results:\n",
            "Train Loss: 0.0159 | Train Acc: 0.9981\n",
            "Val Loss: 0.0063 | Val Acc: 0.9980\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:21<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9 Results:\n",
            "Train Loss: 0.0140 | Train Acc: 0.9984\n",
            "Val Loss: 0.0055 | Val Acc: 0.9983\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:21<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10 Results:\n",
            "Train Loss: 0.0128 | Train Acc: 0.9984\n",
            "Val Loss: 0.0053 | Val Acc: 0.9983\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11 Results:\n",
            "Train Loss: 0.0118 | Train Acc: 0.9985\n",
            "Val Loss: 0.0049 | Val Acc: 0.9985\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:23<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12 Results:\n",
            "Train Loss: 0.0113 | Train Acc: 0.9986\n",
            "Val Loss: 0.0046 | Val Acc: 0.9985\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:20<00:00,  1.11s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 13 Results:\n",
            "Train Loss: 0.0104 | Train Acc: 0.9987\n",
            "Val Loss: 0.0044 | Val Acc: 0.9986\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:23<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 14 Results:\n",
            "Train Loss: 0.0102 | Train Acc: 0.9988\n",
            "Val Loss: 0.0041 | Val Acc: 0.9987\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 15 Results:\n",
            "Train Loss: 0.0094 | Train Acc: 0.9988\n",
            "Val Loss: 0.0039 | Val Acc: 0.9988\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 16 Results:\n",
            "Train Loss: 0.0091 | Train Acc: 0.9989\n",
            "Val Loss: 0.0037 | Val Acc: 0.9988\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 17 Results:\n",
            "Train Loss: 0.0089 | Train Acc: 0.9989\n",
            "Val Loss: 0.0036 | Val Acc: 0.9988\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 18 Results:\n",
            "Train Loss: 0.0086 | Train Acc: 0.9990\n",
            "Val Loss: 0.0035 | Val Acc: 0.9989\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 19 Results:\n",
            "Train Loss: 0.0083 | Train Acc: 0.9990\n",
            "Val Loss: 0.0033 | Val Acc: 0.9989\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 20 Results:\n",
            "Train Loss: 0.0080 | Train Acc: 0.9990\n",
            "Val Loss: 0.0031 | Val Acc: 0.9990\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:21<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 21 Results:\n",
            "Train Loss: 0.0080 | Train Acc: 0.9990\n",
            "Val Loss: 0.0031 | Val Acc: 0.9990\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 22 Results:\n",
            "Train Loss: 0.0074 | Train Acc: 0.9991\n",
            "Val Loss: 0.0029 | Val Acc: 0.9991\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:23<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 23 Results:\n",
            "Train Loss: 0.0073 | Train Acc: 0.9991\n",
            "Val Loss: 0.0029 | Val Acc: 0.9991\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 24 Results:\n",
            "Train Loss: 0.0069 | Train Acc: 0.9992\n",
            "Val Loss: 0.0027 | Val Acc: 0.9991\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:23<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 25 Results:\n",
            "Train Loss: 0.0070 | Train Acc: 0.9992\n",
            "Val Loss: 0.0027 | Val Acc: 0.9991\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:23<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 26 Results:\n",
            "Train Loss: 0.0068 | Train Acc: 0.9992\n",
            "Val Loss: 0.0026 | Val Acc: 0.9991\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:21<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 27 Results:\n",
            "Train Loss: 0.0067 | Train Acc: 0.9992\n",
            "Val Loss: 0.0025 | Val Acc: 0.9992\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:22<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 28 Results:\n",
            "Train Loss: 0.0064 | Train Acc: 0.9992\n",
            "Val Loss: 0.0024 | Val Acc: 0.9992\n",
            "Saved new best model!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 557/557 [10:23<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [00:59<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 29 Results:\n",
            "Train Loss: 0.0064 | Train Acc: 0.9993\n",
            "Val Loss: 0.0024 | Val Acc: 0.9992\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 557/557 [10:23<00:00,  1.12s/it]\n",
            "Evaluating: 100%|██████████| 140/140 [01:00<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 30 Results:\n",
            "Train Loss: 0.0063 | Train Acc: 0.9993\n",
            "Val Loss: 0.0023 | Val Acc: 0.9992\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best_trained_model.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a57905c3ae6d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mtrain_with_best_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-a57905c3ae6d>\u001b[0m in \u001b[0;36mtrain_with_best_config\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# Load the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_trained_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# Final evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_trained_model.pth'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Vocabulary Class\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.char2idx = {}\n",
        "        self.idx2char = {}\n",
        "        self.pad_token = 0\n",
        "        self.sos_token = 1\n",
        "        self.eos_token = 2\n",
        "        self.unk_token = 3\n",
        "        self._build_vocab()\n",
        "\n",
        "    def _build_vocab(self):\n",
        "        special_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
        "        all_chars = list(string.printable)\n",
        "\n",
        "        self.char2idx = {token: idx for idx, token in enumerate(special_tokens)}\n",
        "        self.char2idx.update({char: idx+len(special_tokens) for idx, char in enumerate(all_chars)})\n",
        "        self.idx2char = {idx: char for char, idx in self.char2idx.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.char2idx)\n",
        "\n",
        "    def encode(self, text):\n",
        "        return [self.char2idx.get(char, self.unk_token) for char in text]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        return ''.join([self.idx2char.get(idx, '<UNK>') for idx in indices if idx not in {self.pad_token, self.sos_token, self.eos_token}])\n",
        "\n",
        "# Data Preparation\n",
        "def load_data(file_path, max_samples=800000):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Filter rows where 'Output' length is <=200\n",
        "    df = df[df['Output'].str.len() <= 200]\n",
        "\n",
        "    # Randomly select samples (if available)\n",
        "    if len(df) > max_samples:\n",
        "        df = df.sample(n=max_samples, random_state=42)\n",
        "\n",
        "    inputs = df['Input'].tolist()\n",
        "    outputs = df['Output'].tolist()\n",
        "\n",
        "    return inputs, outputs\n",
        "\n",
        "# Dataset Class\n",
        "class CipherDataset(data.Dataset):\n",
        "    def __init__(self, inputs, outputs, vocab, max_length):\n",
        "        self.inputs = inputs\n",
        "        self.outputs = outputs\n",
        "        self.vocab = vocab\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = str(self.inputs[idx])\n",
        "        output_text = str(self.outputs[idx])\n",
        "\n",
        "        input_encoded = [self.vocab.sos_token] + self.vocab.encode(input_text) + [self.vocab.eos_token]\n",
        "        output_encoded = [self.vocab.sos_token] + self.vocab.encode(output_text) + [self.vocab.eos_token]\n",
        "\n",
        "        input_padded = input_encoded + [self.vocab.pad_token] * (self.max_length - len(input_encoded))\n",
        "        output_padded = output_encoded + [self.vocab.pad_token] * (self.max_length - len(output_encoded))\n",
        "\n",
        "        input_padded = input_padded[:self.max_length]\n",
        "        output_padded = output_padded[:self.max_length]\n",
        "\n",
        "        return torch.tensor(input_padded), torch.tensor(output_padded)\n",
        "\n",
        "# Transformer Model\n",
        "class CaesarTransformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # Simplified positional encoding (learned instead of fixed)\n",
        "        self.encoder_pos = nn.Embedding(max_seq_length, d_model)\n",
        "        self.decoder_pos = nn.Embedding(max_seq_length, d_model)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(d_model, num_heads, d_ff, dropout, batch_first=True)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            nn.TransformerDecoderLayer(d_model, num_heads, d_ff, dropout, batch_first=True)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Create masks\n",
        "        src_mask = (src == 0)\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(device)\n",
        "\n",
        "        # Embed and add positional encoding\n",
        "        src_pos = torch.arange(0, src.size(1), device=device).unsqueeze(0)\n",
        "        tgt_pos = torch.arange(0, tgt.size(1), device=device).unsqueeze(0)\n",
        "\n",
        "        src_embedded = self.dropout(self.encoder_embedding(src) + self.encoder_pos(src_pos))\n",
        "        tgt_embedded = self.dropout(self.decoder_embedding(tgt) + self.decoder_pos(tgt_pos))\n",
        "\n",
        "        # Encoder\n",
        "        memory = src_embedded\n",
        "        for layer in self.encoder_layers:\n",
        "            memory = layer(memory, src_key_padding_mask=src_mask)\n",
        "\n",
        "        # Decoder\n",
        "        output = tgt_embedded\n",
        "        for layer in self.decoder_layers:\n",
        "            output = layer(output, memory, tgt_mask=tgt_mask, memory_key_padding_mask=src_mask)\n",
        "\n",
        "        return self.fc(output)\n",
        "\n",
        "# Training and Evaluation Functions\n",
        "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt in tqdm(train_loader, desc=\"Training\"):\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt[:, :-1])\n",
        "        loss = criterion(output.contiguous().view(-1, output.size(-1)),\n",
        "                        tgt[:, 1:].contiguous().view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            loss = criterion(output.contiguous().view(-1, output.size(-1)),\n",
        "                            tgt[:, 1:].contiguous().view(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "def calculate_accuracy(model, data_loader, vocab, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in data_loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            predictions = output.argmax(dim=-1)\n",
        "            correct += ((predictions == tgt[:, 1:]) & (tgt[:, 1:] != vocab.pad_token)).sum().item()\n",
        "            total += (tgt[:, 1:] != vocab.pad_token).sum().item()\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "def decrypt_text(model, text, vocab, max_length, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded = [vocab.sos_token] + vocab.encode(str(text)) + [vocab.eos_token]\n",
        "        encoded = encoded + [vocab.pad_token] * (max_length - len(encoded))\n",
        "        encoded = torch.tensor(encoded[:max_length]).unsqueeze(0).to(device)\n",
        "\n",
        "        target = torch.tensor([[vocab.sos_token]]).to(device)\n",
        "\n",
        "        for _ in range(max_length - 1):\n",
        "            output = model(encoded, target)\n",
        "            next_token = output.argmax(2)[:, -1].item()\n",
        "            if next_token == vocab.eos_token:\n",
        "                break\n",
        "            target = torch.cat([target, torch.tensor([[next_token]]).to(device)], dim=1)\n",
        "\n",
        "        decrypted = vocab.decode(target[0].cpu().numpy())\n",
        "        return decrypted\n",
        "\n",
        "# Main Training Function\n",
        "def train_with_best_config():\n",
        "    # Load and prepare data\n",
        "    inputs, outputs = load_data('training_newshift_1.csv')\n",
        "    vocab = Vocabulary()\n",
        "    max_length = 256\n",
        "\n",
        "    # Split data\n",
        "    train_inputs, val_inputs, train_outputs, val_outputs = train_test_split(\n",
        "        inputs, outputs, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CipherDataset(train_inputs, train_outputs, vocab, max_length)\n",
        "    val_dataset = CipherDataset(val_inputs, val_outputs, vocab, max_length)\n",
        "\n",
        "    # Best hyperparameters from Optuna\n",
        "    best_config = {\n",
        "        \"d_model\": 256,\n",
        "        \"num_heads\": 4,\n",
        "        \"num_layers\": 4,\n",
        "        \"d_ff\": 256,\n",
        "        \"dropout\": 0.2207862787473907,\n",
        "        \"batch_size\": 1150,\n",
        "        \"learning_rate\": 0.0005\n",
        "    }\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = data.DataLoader(train_dataset, batch_size=best_config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = data.DataLoader(val_dataset, batch_size=best_config[\"batch_size\"])\n",
        "\n",
        "    # Initialize model\n",
        "    model = CaesarTransformer(\n",
        "        src_vocab_size=len(vocab),\n",
        "        tgt_vocab_size=len(vocab),\n",
        "        d_model=best_config[\"d_model\"],\n",
        "        num_heads=best_config[\"num_heads\"],\n",
        "        num_layers=best_config[\"num_layers\"],\n",
        "        d_ff=best_config[\"d_ff\"],\n",
        "        max_seq_length=max_length,\n",
        "        dropout=best_config[\"dropout\"]\n",
        "    ).to(device)\n",
        "\n",
        "    # Training setup\n",
        "    optimizer = optim.Adam(model.parameters(), lr=best_config[\"learning_rate\"])\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=vocab.pad_token)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
        "\n",
        "    # Training parameters\n",
        "    epochs = 30\n",
        "    patience = 5\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        # Train epoch\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "        # Evaluate\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Calculate accuracies\n",
        "        train_acc = calculate_accuracy(model, train_loader, vocab, device)\n",
        "        val_acc = calculate_accuracy(model, val_loader, vocab, device)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1} Results:\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Check for improvement\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/best_trained_model.pth')\n",
        "            print(\"Saved new best model!\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                print(f\"\\nEarly stopping after {epoch+1} epochs!\")\n",
        "                break\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/best_trained_model.pth'))\n",
        "\n",
        "    # Final evaluation\n",
        "    final_train_loss = evaluate(model, train_loader, criterion, device)\n",
        "    final_val_loss = evaluate(model, val_loader, criterion, device)\n",
        "    final_train_acc = calculate_accuracy(model, train_loader, vocab, device)\n",
        "    final_val_acc = calculate_accuracy(model, val_loader, vocab, device)\n",
        "\n",
        "    print(\"\\nFinal Training Results:\")\n",
        "    print(f\"Train Loss: {final_train_loss:.4f} | Train Acc: {final_train_acc:.4f}\")\n",
        "    print(f\"Val Loss: {final_val_loss:.4f} | Val Acc: {final_val_acc:.4f}\")\n",
        "\n",
        "    # Test decryption\n",
        "    test_cases = [\n",
        "        (\"Please decrypt the following using Caesar cipher: gfbs\", \"fear\"),\n",
        "        (\"Please decrypt the following using Caesar cipher: dpnqvufs\", \"computer\"),\n",
        "        (\"Please decrypt the following using Caesar cipher: xibu\", \"what\"),\n",
        "        (\"Please decrypt the following using Caesar cipher: ifmmp\", \"hello\"),\n",
        "        (\"Please decrypt the following using Caesar cipher: uijt\", \"this\")\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTest Decryptions:\")\n",
        "    for encrypted, expected in test_cases:\n",
        "        decrypted = decrypt_text(model, encrypted, vocab, max_length, device)\n",
        "        print(f\"Input: '{encrypted}' | Output: '{decrypted}' | Expected: '{expected}' | {'✓' if decrypted == expected else '✗'}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_with_best_config()"
      ]
    }
  ]
}