{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH07NxOfZV4P",
        "outputId": "92675c11-1583-42f0-d962-a919e1de0803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000\n",
            "Epoch: 1, Batch: 0, Loss: 4.8541\n",
            "Epoch: 1, Batch: 10, Loss: 3.0420\n",
            "Epoch: 1, Batch: 20, Loss: 2.7111\n",
            "Epoch: 1, Batch: 30, Loss: 2.4810\n",
            "Epoch: 1, Batch: 40, Loss: 2.3571\n",
            "Epoch: 1, Batch: 50, Loss: 2.3084\n",
            "Epoch: 1, Batch: 60, Loss: 2.2884\n",
            "Epoch: 1, Batch: 70, Loss: 2.2451\n",
            "Epoch: 1, Batch: 80, Loss: 2.2083\n",
            "Epoch: 1, Batch: 90, Loss: 2.1555\n",
            "Epoch: 1, Batch: 100, Loss: 2.2000\n",
            "Epoch: 1, Batch: 110, Loss: 2.1208\n",
            "Epoch: 1, Batch: 120, Loss: 2.1124\n",
            "Epoch: 1, Batch: 130, Loss: 2.0581\n",
            "Epoch: 1, Batch: 140, Loss: 2.0253\n",
            "Epoch: 1, Batch: 150, Loss: 2.0161\n",
            "Epoch: 1, Batch: 160, Loss: 1.9935\n",
            "Epoch: 1, Batch: 170, Loss: 1.9663\n",
            "Epoch: 1, Batch: 180, Loss: 1.9600\n",
            "Epoch: 1, Batch: 190, Loss: 1.9514\n",
            "Epoch: 1, Batch: 200, Loss: 1.8860\n",
            "Epoch: 1, Batch: 210, Loss: 1.8720\n",
            "Epoch: 1, Batch: 220, Loss: 1.8694\n",
            "Epoch: 1, Batch: 230, Loss: 1.8320\n",
            "Epoch: 1, Batch: 240, Loss: 1.8859\n",
            "Epoch: 1, Batch: 250, Loss: 1.7879\n",
            "Epoch: 1, Batch: 260, Loss: 1.8127\n",
            "Epoch: 1, Batch: 270, Loss: 1.7437\n",
            "Epoch: 1, Batch: 280, Loss: 1.7609\n",
            "Epoch: 1, Batch: 290, Loss: 1.7147\n",
            "Epoch: 1, Batch: 300, Loss: 1.7513\n",
            "Epoch: 1, Batch: 310, Loss: 1.6537\n",
            "Epoch: 1, Batch: 320, Loss: 1.6854\n",
            "Epoch: 1, Batch: 330, Loss: 1.6851\n",
            "Epoch: 1, Batch: 340, Loss: 1.6554\n",
            "Epoch: 1, Batch: 350, Loss: 1.6623\n",
            "Epoch: 1, Batch: 360, Loss: 1.6744\n",
            "Epoch: 1, Batch: 370, Loss: 1.6390\n",
            "Epoch: 1, Batch: 380, Loss: 1.6443\n",
            "Epoch: 1, Batch: 390, Loss: 1.6016\n",
            "Epoch: 1, Batch: 400, Loss: 1.5425\n",
            "Epoch: 1, Batch: 410, Loss: 1.6957\n",
            "Epoch: 1, Batch: 420, Loss: 1.5952\n",
            "Epoch: 1, Batch: 430, Loss: 1.5236\n",
            "Epoch: 1, Batch: 440, Loss: 1.5422\n",
            "Epoch: 1, Batch: 450, Loss: 1.5710\n",
            "Epoch: 1, Batch: 460, Loss: 1.5055\n",
            "Epoch: 1, Batch: 470, Loss: 1.5316\n",
            "Epoch: 1, Batch: 480, Loss: 1.4870\n",
            "Epoch: 1, Batch: 490, Loss: 1.5091\n",
            "Epoch: 1, Batch: 500, Loss: 1.4693\n",
            "Epoch: 1, Batch: 510, Loss: 1.4144\n",
            "Epoch: 1, Batch: 520, Loss: 1.4844\n",
            "Epoch: 1, Batch: 530, Loss: 1.4413\n",
            "Epoch: 1, Batch: 540, Loss: 1.4584\n",
            "Epoch: 1, Batch: 550, Loss: 1.4749\n",
            "Epoch: 1, Batch: 560, Loss: 1.4150\n",
            "Epoch: 1, Batch: 570, Loss: 1.3845\n",
            "Epoch: 1, Batch: 580, Loss: 1.4068\n",
            "Epoch: 1, Batch: 590, Loss: 1.3451\n",
            "Epoch: 1, Batch: 600, Loss: 1.4295\n",
            "Epoch: 1, Batch: 610, Loss: 1.3987\n",
            "Epoch: 1, Batch: 620, Loss: 1.4131\n",
            "Epoch: 1, Batch: 630, Loss: 1.3389\n",
            "Epoch: 1, Batch: 640, Loss: 1.3221\n",
            "Epoch: 1, Batch: 650, Loss: 1.3567\n",
            "Epoch: 1, Batch: 660, Loss: 1.3706\n",
            "Epoch: 1, Batch: 670, Loss: 1.3834\n",
            "Epoch: 1, Batch: 680, Loss: 1.3186\n",
            "Epoch: 1, Batch: 690, Loss: 1.2645\n",
            "Epoch: 1, Batch: 700, Loss: 1.2960\n",
            "Epoch: 1, Batch: 710, Loss: 1.3290\n",
            "Epoch: 1, Batch: 720, Loss: 1.2893\n",
            "Epoch: 1, Batch: 730, Loss: 1.3031\n",
            "Epoch: 1, Batch: 740, Loss: 1.3257\n",
            "Epoch: 1, Batch: 750, Loss: 1.2084\n",
            "Epoch: 1, Batch: 760, Loss: 1.3336\n",
            "Epoch: 1, Batch: 770, Loss: 1.2217\n",
            "Epoch: 1, Batch: 780, Loss: 1.2369\n",
            "Epoch: 1, Batch: 790, Loss: 1.2464\n",
            "Epoch: 1, Batch: 800, Loss: 1.3121\n",
            "Epoch: 1, Batch: 810, Loss: 1.2188\n",
            "Epoch: 1, Batch: 820, Loss: 1.2779\n",
            "Epoch: 1, Batch: 830, Loss: 1.1803\n",
            "Epoch: 1, Batch: 840, Loss: 1.2531\n",
            "Epoch: 1, Batch: 850, Loss: 1.1829\n",
            "Epoch: 1, Batch: 860, Loss: 1.1956\n",
            "Epoch: 1, Batch: 870, Loss: 1.1879\n",
            "Epoch: 1, Batch: 880, Loss: 1.1837\n",
            "Epoch: 1, Batch: 890, Loss: 1.1325\n",
            "Epoch: 1, Batch: 900, Loss: 1.1429\n",
            "Epoch: 1, Batch: 910, Loss: 1.1694\n",
            "Epoch: 1, Batch: 920, Loss: 1.1523\n",
            "Epoch: 1, Batch: 930, Loss: 1.1581\n",
            "Epoch: 1, Batch: 940, Loss: 1.1072\n",
            "Epoch: 1, Batch: 950, Loss: 1.1433\n",
            "Epoch: 1, Batch: 960, Loss: 1.1376\n",
            "Epoch: 1, Batch: 970, Loss: 1.1169\n",
            "Epoch: 1, Batch: 980, Loss: 1.0993\n",
            "Epoch: 1, Batch: 990, Loss: 1.1308\n",
            "Epoch: 1, Batch: 1000, Loss: 1.1340\n",
            "Epoch: 1, Batch: 1010, Loss: 1.1347\n",
            "Epoch: 1, Batch: 1020, Loss: 1.1272\n",
            "Epoch: 1, Batch: 1030, Loss: 1.0680\n",
            "Epoch: 1, Batch: 1040, Loss: 1.0452\n",
            "Epoch: 1, Batch: 1050, Loss: 1.0977\n",
            "Epoch: 1, Batch: 1060, Loss: 1.0834\n",
            "Epoch: 1, Batch: 1070, Loss: 1.0926\n",
            "Epoch: 1, Batch: 1080, Loss: 1.0979\n",
            "Epoch: 1, Batch: 1090, Loss: 1.0784\n",
            "Epoch: 1, Batch: 1100, Loss: 1.0118\n",
            "Epoch: 1, Batch: 1110, Loss: 1.0601\n",
            "Epoch: 1, Batch: 1120, Loss: 1.1115\n",
            "Epoch: 1, Batch: 1130, Loss: 1.0531\n",
            "Epoch: 1, Batch: 1140, Loss: 1.0235\n",
            "Epoch: 1, Batch: 1150, Loss: 1.0526\n",
            "Epoch: 1, Batch: 1160, Loss: 1.0779\n",
            "Epoch: 1, Batch: 1170, Loss: 1.0554\n",
            "Epoch: 1, Batch: 1180, Loss: 1.0120\n",
            "Epoch: 1, Batch: 1190, Loss: 1.0800\n",
            "Epoch: 1, Batch: 1200, Loss: 1.0550\n",
            "Epoch: 1, Batch: 1210, Loss: 1.0124\n",
            "Epoch: 1, Batch: 1220, Loss: 0.9970\n",
            "Epoch: 1, Batch: 1230, Loss: 1.0158\n",
            "Epoch: 1, Batch: 1240, Loss: 1.0305\n",
            "Epoch: 1, Batch: 1250, Loss: 0.9581\n",
            "Epoch: 1, Batch: 1260, Loss: 0.9704\n",
            "Epoch: 1, Batch: 1270, Loss: 1.0068\n",
            "Epoch: 1, Batch: 1280, Loss: 0.9741\n",
            "Epoch: 1, Batch: 1290, Loss: 0.9676\n",
            "Epoch: 1, Batch: 1300, Loss: 0.9746\n",
            "Epoch: 1, Batch: 1310, Loss: 0.9206\n",
            "Epoch: 1, Batch: 1320, Loss: 0.9289\n",
            "Epoch: 1, Batch: 1330, Loss: 0.9431\n",
            "Epoch: 1, Batch: 1340, Loss: 0.9333\n",
            "Epoch: 1, Batch: 1350, Loss: 0.9253\n",
            "Epoch: 1, Batch: 1360, Loss: 0.9065\n",
            "Epoch: 1, Batch: 1370, Loss: 0.9826\n",
            "Epoch: 1, Batch: 1380, Loss: 0.9375\n",
            "Epoch: 1, Batch: 1390, Loss: 0.9129\n",
            "Epoch: 1, Batch: 1400, Loss: 0.9415\n",
            "Epoch: 1, Batch: 1410, Loss: 0.9076\n",
            "Epoch: 1, Batch: 1420, Loss: 0.8779\n",
            "Epoch: 1, Batch: 1430, Loss: 0.9141\n",
            "Epoch: 1, Batch: 1440, Loss: 0.8739\n",
            "Epoch: 1, Batch: 1450, Loss: 0.9124\n",
            "Epoch: 1, Train Loss: 1.4060, Val Loss: 0.8023\n",
            "Epoch: 2, Batch: 0, Loss: 0.8229\n",
            "Epoch: 2, Batch: 10, Loss: 0.8284\n",
            "Epoch: 2, Batch: 20, Loss: 0.7929\n",
            "Epoch: 2, Batch: 30, Loss: 0.7734\n",
            "Epoch: 2, Batch: 40, Loss: 0.8092\n",
            "Epoch: 2, Batch: 50, Loss: 0.7294\n",
            "Epoch: 2, Batch: 60, Loss: 0.7326\n",
            "Epoch: 2, Batch: 70, Loss: 0.7360\n",
            "Epoch: 2, Batch: 80, Loss: 0.7409\n",
            "Epoch: 2, Batch: 90, Loss: 0.7197\n",
            "Epoch: 2, Batch: 100, Loss: 0.7143\n",
            "Epoch: 2, Batch: 110, Loss: 0.7317\n",
            "Epoch: 2, Batch: 120, Loss: 0.7009\n",
            "Epoch: 2, Batch: 130, Loss: 0.6956\n",
            "Epoch: 2, Batch: 140, Loss: 0.6967\n",
            "Epoch: 2, Batch: 150, Loss: 0.6624\n",
            "Epoch: 2, Batch: 160, Loss: 0.6537\n",
            "Epoch: 2, Batch: 170, Loss: 0.6619\n",
            "Epoch: 2, Batch: 180, Loss: 0.6309\n",
            "Epoch: 2, Batch: 190, Loss: 0.6477\n",
            "Epoch: 2, Batch: 200, Loss: 0.6312\n",
            "Epoch: 2, Batch: 210, Loss: 0.5847\n",
            "Epoch: 2, Batch: 220, Loss: 0.5911\n",
            "Epoch: 2, Batch: 230, Loss: 0.6437\n",
            "Epoch: 2, Batch: 240, Loss: 0.5784\n",
            "Epoch: 2, Batch: 250, Loss: 0.5775\n",
            "Epoch: 2, Batch: 260, Loss: 0.5879\n",
            "Epoch: 2, Batch: 270, Loss: 0.5725\n",
            "Epoch: 2, Batch: 280, Loss: 0.5800\n",
            "Epoch: 2, Batch: 290, Loss: 0.5655\n",
            "Epoch: 2, Batch: 300, Loss: 0.5478\n",
            "Epoch: 2, Batch: 310, Loss: 0.5279\n",
            "Epoch: 2, Batch: 320, Loss: 0.5300\n",
            "Epoch: 2, Batch: 330, Loss: 0.5253\n",
            "Epoch: 2, Batch: 340, Loss: 0.5049\n",
            "Epoch: 2, Batch: 350, Loss: 0.5067\n",
            "Epoch: 2, Batch: 360, Loss: 0.5239\n",
            "Epoch: 2, Batch: 370, Loss: 0.4849\n",
            "Epoch: 2, Batch: 380, Loss: 0.4862\n",
            "Epoch: 2, Batch: 390, Loss: 0.5147\n",
            "Epoch: 2, Batch: 400, Loss: 0.4652\n",
            "Epoch: 2, Batch: 410, Loss: 0.4705\n",
            "Epoch: 2, Batch: 420, Loss: 0.4663\n",
            "Epoch: 2, Batch: 430, Loss: 0.4777\n",
            "Epoch: 2, Batch: 440, Loss: 0.4231\n",
            "Epoch: 2, Batch: 450, Loss: 0.4380\n",
            "Epoch: 2, Batch: 460, Loss: 0.4291\n",
            "Epoch: 2, Batch: 470, Loss: 0.4317\n",
            "Epoch: 2, Batch: 480, Loss: 0.4308\n",
            "Epoch: 2, Batch: 490, Loss: 0.4401\n",
            "Epoch: 2, Batch: 500, Loss: 0.4210\n",
            "Epoch: 2, Batch: 510, Loss: 0.3998\n",
            "Epoch: 2, Batch: 520, Loss: 0.3882\n",
            "Epoch: 2, Batch: 530, Loss: 0.3918\n",
            "Epoch: 2, Batch: 540, Loss: 0.3900\n",
            "Epoch: 2, Batch: 550, Loss: 0.3909\n",
            "Epoch: 2, Batch: 560, Loss: 0.3804\n",
            "Epoch: 2, Batch: 570, Loss: 0.3806\n",
            "Epoch: 2, Batch: 580, Loss: 0.3695\n",
            "Epoch: 2, Batch: 590, Loss: 0.3394\n",
            "Epoch: 2, Batch: 600, Loss: 0.3486\n",
            "Epoch: 2, Batch: 610, Loss: 0.3364\n",
            "Epoch: 2, Batch: 620, Loss: 0.3487\n",
            "Epoch: 2, Batch: 630, Loss: 0.3395\n",
            "Epoch: 2, Batch: 640, Loss: 0.3210\n",
            "Epoch: 2, Batch: 650, Loss: 0.3269\n",
            "Epoch: 2, Batch: 660, Loss: 0.3213\n",
            "Epoch: 2, Batch: 670, Loss: 0.3084\n",
            "Epoch: 2, Batch: 680, Loss: 0.3271\n",
            "Epoch: 2, Batch: 690, Loss: 0.2859\n",
            "Epoch: 2, Batch: 700, Loss: 0.2998\n",
            "Epoch: 2, Batch: 710, Loss: 0.3018\n",
            "Epoch: 2, Batch: 720, Loss: 0.3008\n",
            "Epoch: 2, Batch: 730, Loss: 0.3022\n",
            "Epoch: 2, Batch: 740, Loss: 0.2851\n",
            "Epoch: 2, Batch: 750, Loss: 0.2914\n",
            "Epoch: 2, Batch: 760, Loss: 0.2770\n",
            "Epoch: 2, Batch: 770, Loss: 0.2786\n",
            "Epoch: 2, Batch: 780, Loss: 0.2767\n",
            "Epoch: 2, Batch: 790, Loss: 0.2760\n",
            "Epoch: 2, Batch: 800, Loss: 0.2816\n",
            "Epoch: 2, Batch: 810, Loss: 0.2511\n",
            "Epoch: 2, Batch: 820, Loss: 0.2498\n",
            "Epoch: 2, Batch: 830, Loss: 0.2572\n",
            "Epoch: 2, Batch: 840, Loss: 0.2489\n",
            "Epoch: 2, Batch: 850, Loss: 0.2465\n",
            "Epoch: 2, Batch: 860, Loss: 0.2722\n",
            "Epoch: 2, Batch: 870, Loss: 0.2415\n",
            "Epoch: 2, Batch: 880, Loss: 0.2463\n",
            "Epoch: 2, Batch: 890, Loss: 0.2522\n",
            "Epoch: 2, Batch: 900, Loss: 0.2220\n",
            "Epoch: 2, Batch: 910, Loss: 0.2344\n",
            "Epoch: 2, Batch: 920, Loss: 0.2421\n",
            "Epoch: 2, Batch: 930, Loss: 0.2288\n",
            "Epoch: 2, Batch: 940, Loss: 0.2448\n",
            "Epoch: 2, Batch: 950, Loss: 0.2587\n",
            "Epoch: 2, Batch: 960, Loss: 0.2144\n",
            "Epoch: 2, Batch: 970, Loss: 0.2218\n",
            "Epoch: 2, Batch: 980, Loss: 0.2227\n",
            "Epoch: 2, Batch: 990, Loss: 0.2139\n",
            "Epoch: 2, Batch: 1000, Loss: 0.2186\n",
            "Epoch: 2, Batch: 1010, Loss: 0.2076\n",
            "Epoch: 2, Batch: 1020, Loss: 0.2119\n",
            "Epoch: 2, Batch: 1030, Loss: 0.2186\n",
            "Epoch: 2, Batch: 1040, Loss: 0.2086\n",
            "Epoch: 2, Batch: 1050, Loss: 0.2270\n",
            "Epoch: 2, Batch: 1060, Loss: 0.2156\n",
            "Epoch: 2, Batch: 1070, Loss: 0.2184\n",
            "Epoch: 2, Batch: 1080, Loss: 0.2144\n",
            "Epoch: 2, Batch: 1090, Loss: 0.1980\n",
            "Epoch: 2, Batch: 1100, Loss: 0.2087\n",
            "Epoch: 2, Batch: 1110, Loss: 0.1932\n",
            "Epoch: 2, Batch: 1120, Loss: 0.1969\n",
            "Epoch: 2, Batch: 1130, Loss: 0.1878\n",
            "Epoch: 2, Batch: 1140, Loss: 0.2137\n",
            "Epoch: 2, Batch: 1150, Loss: 0.1739\n",
            "Epoch: 2, Batch: 1160, Loss: 0.2006\n",
            "Epoch: 2, Batch: 1170, Loss: 0.1875\n",
            "Epoch: 2, Batch: 1180, Loss: 0.2024\n",
            "Epoch: 2, Batch: 1190, Loss: 0.1969\n",
            "Epoch: 2, Batch: 1200, Loss: 0.1930\n",
            "Epoch: 2, Batch: 1210, Loss: 0.1965\n",
            "Epoch: 2, Batch: 1220, Loss: 0.1862\n",
            "Epoch: 2, Batch: 1230, Loss: 0.2009\n",
            "Epoch: 2, Batch: 1240, Loss: 0.1780\n",
            "Epoch: 2, Batch: 1250, Loss: 0.1859\n",
            "Epoch: 2, Batch: 1260, Loss: 0.1804\n",
            "Epoch: 2, Batch: 1270, Loss: 0.1615\n",
            "Epoch: 2, Batch: 1280, Loss: 0.1767\n",
            "Epoch: 2, Batch: 1290, Loss: 0.2096\n",
            "Epoch: 2, Batch: 1300, Loss: 0.1672\n",
            "Epoch: 2, Batch: 1310, Loss: 0.1979\n",
            "Epoch: 2, Batch: 1320, Loss: 0.1716\n",
            "Epoch: 2, Batch: 1330, Loss: 0.1789\n",
            "Epoch: 2, Batch: 1340, Loss: 0.1969\n",
            "Epoch: 2, Batch: 1350, Loss: 0.1741\n",
            "Epoch: 2, Batch: 1360, Loss: 0.1575\n",
            "Epoch: 2, Batch: 1370, Loss: 0.1695\n",
            "Epoch: 2, Batch: 1380, Loss: 0.1752\n",
            "Epoch: 2, Batch: 1390, Loss: 0.1891\n",
            "Epoch: 2, Batch: 1400, Loss: 0.1829\n",
            "Epoch: 2, Batch: 1410, Loss: 0.1819\n",
            "Epoch: 2, Batch: 1420, Loss: 0.1610\n",
            "Epoch: 2, Batch: 1430, Loss: 0.1712\n",
            "Epoch: 2, Batch: 1440, Loss: 0.1681\n",
            "Epoch: 2, Batch: 1450, Loss: 0.1529\n",
            "Epoch: 2, Train Loss: 0.3653, Val Loss: 0.1712\n",
            "Epoch: 3, Batch: 0, Loss: 0.1444\n",
            "Epoch: 3, Batch: 10, Loss: 0.1745\n",
            "Epoch: 3, Batch: 20, Loss: 0.1690\n",
            "Epoch: 3, Batch: 30, Loss: 0.1540\n",
            "Epoch: 3, Batch: 40, Loss: 0.1645\n",
            "Epoch: 3, Batch: 50, Loss: 0.1558\n",
            "Epoch: 3, Batch: 60, Loss: 0.1841\n",
            "Epoch: 3, Batch: 70, Loss: 0.1489\n",
            "Epoch: 3, Batch: 80, Loss: 0.1554\n",
            "Epoch: 3, Batch: 90, Loss: 0.1622\n",
            "Epoch: 3, Batch: 100, Loss: 0.1557\n",
            "Epoch: 3, Batch: 110, Loss: 0.1753\n",
            "Epoch: 3, Batch: 120, Loss: 0.1662\n",
            "Epoch: 3, Batch: 130, Loss: 0.1679\n",
            "Epoch: 3, Batch: 140, Loss: 0.1588\n",
            "Epoch: 3, Batch: 150, Loss: 0.1608\n",
            "Epoch: 3, Batch: 160, Loss: 0.1502\n",
            "Epoch: 3, Batch: 170, Loss: 0.1757\n",
            "Epoch: 3, Batch: 180, Loss: 0.1667\n",
            "Epoch: 3, Batch: 190, Loss: 0.1519\n",
            "Epoch: 3, Batch: 200, Loss: 0.1536\n",
            "Epoch: 3, Batch: 210, Loss: 0.1501\n",
            "Epoch: 3, Batch: 220, Loss: 0.1441\n",
            "Epoch: 3, Batch: 230, Loss: 0.1473\n",
            "Epoch: 3, Batch: 240, Loss: 0.1625\n",
            "Epoch: 3, Batch: 250, Loss: 0.1395\n",
            "Epoch: 3, Batch: 260, Loss: 0.1425\n",
            "Epoch: 3, Batch: 270, Loss: 0.1666\n",
            "Epoch: 3, Batch: 280, Loss: 0.1495\n",
            "Epoch: 3, Batch: 290, Loss: 0.1491\n",
            "Epoch: 3, Batch: 300, Loss: 0.1556\n",
            "Epoch: 3, Batch: 310, Loss: 0.1471\n",
            "Epoch: 3, Batch: 320, Loss: 0.1277\n",
            "Epoch: 3, Batch: 330, Loss: 0.1518\n",
            "Epoch: 3, Batch: 340, Loss: 0.1363\n",
            "Epoch: 3, Batch: 350, Loss: 0.1429\n",
            "Epoch: 3, Batch: 360, Loss: 0.1467\n",
            "Epoch: 3, Batch: 370, Loss: 0.1452\n",
            "Epoch: 3, Batch: 380, Loss: 0.1342\n",
            "Epoch: 3, Batch: 390, Loss: 0.1530\n",
            "Epoch: 3, Batch: 400, Loss: 0.1500\n",
            "Epoch: 3, Batch: 410, Loss: 0.1166\n",
            "Epoch: 3, Batch: 420, Loss: 0.1472\n",
            "Epoch: 3, Batch: 430, Loss: 0.1263\n",
            "Epoch: 3, Batch: 440, Loss: 0.1394\n",
            "Epoch: 3, Batch: 450, Loss: 0.1357\n",
            "Epoch: 3, Batch: 460, Loss: 0.1510\n",
            "Epoch: 3, Batch: 470, Loss: 0.1311\n",
            "Epoch: 3, Batch: 480, Loss: 0.1364\n",
            "Epoch: 3, Batch: 490, Loss: 0.1378\n",
            "Epoch: 3, Batch: 500, Loss: 0.1535\n",
            "Epoch: 3, Batch: 510, Loss: 0.1594\n",
            "Epoch: 3, Batch: 520, Loss: 0.1534\n",
            "Epoch: 3, Batch: 530, Loss: 0.1447\n",
            "Epoch: 3, Batch: 540, Loss: 0.1179\n",
            "Epoch: 3, Batch: 550, Loss: 0.1318\n",
            "Epoch: 3, Batch: 560, Loss: 0.1429\n",
            "Epoch: 3, Batch: 570, Loss: 0.1223\n",
            "Epoch: 3, Batch: 580, Loss: 0.1364\n",
            "Epoch: 3, Batch: 590, Loss: 0.1319\n",
            "Epoch: 3, Batch: 600, Loss: 0.1261\n",
            "Epoch: 3, Batch: 610, Loss: 0.1459\n",
            "Epoch: 3, Batch: 620, Loss: 0.1301\n",
            "Epoch: 3, Batch: 630, Loss: 0.1207\n",
            "Epoch: 3, Batch: 640, Loss: 0.1361\n",
            "Epoch: 3, Batch: 650, Loss: 0.1238\n",
            "Epoch: 3, Batch: 660, Loss: 0.1400\n",
            "Epoch: 3, Batch: 670, Loss: 0.1158\n",
            "Epoch: 3, Batch: 680, Loss: 0.1236\n",
            "Epoch: 3, Batch: 690, Loss: 0.1238\n",
            "Epoch: 3, Batch: 700, Loss: 0.1284\n",
            "Epoch: 3, Batch: 710, Loss: 0.1117\n",
            "Epoch: 3, Batch: 720, Loss: 0.1219\n",
            "Epoch: 3, Batch: 730, Loss: 0.1169\n",
            "Epoch: 3, Batch: 740, Loss: 0.1279\n",
            "Epoch: 3, Batch: 750, Loss: 0.1326\n",
            "Epoch: 3, Batch: 760, Loss: 0.1386\n",
            "Epoch: 3, Batch: 770, Loss: 0.1230\n",
            "Epoch: 3, Batch: 780, Loss: 0.1224\n",
            "Epoch: 3, Batch: 790, Loss: 0.1171\n",
            "Epoch: 3, Batch: 800, Loss: 0.1141\n",
            "Epoch: 3, Batch: 810, Loss: 0.1150\n",
            "Epoch: 3, Batch: 820, Loss: 0.1252\n",
            "Epoch: 3, Batch: 830, Loss: 0.1133\n",
            "Epoch: 3, Batch: 840, Loss: 0.1081\n",
            "Epoch: 3, Batch: 850, Loss: 0.1250\n",
            "Epoch: 3, Batch: 860, Loss: 0.1375\n",
            "Epoch: 3, Batch: 870, Loss: 0.1387\n",
            "Epoch: 3, Batch: 880, Loss: 0.1354\n",
            "Epoch: 3, Batch: 890, Loss: 0.1324\n",
            "Epoch: 3, Batch: 900, Loss: 0.1000\n",
            "Epoch: 3, Batch: 910, Loss: 0.1113\n",
            "Epoch: 3, Batch: 920, Loss: 0.1319\n",
            "Epoch: 3, Batch: 930, Loss: 0.1160\n",
            "Epoch: 3, Batch: 940, Loss: 0.1404\n",
            "Epoch: 3, Batch: 950, Loss: 0.1054\n",
            "Epoch: 3, Batch: 960, Loss: 0.1220\n",
            "Epoch: 3, Batch: 970, Loss: 0.1038\n",
            "Epoch: 3, Batch: 980, Loss: 0.1099\n",
            "Epoch: 3, Batch: 990, Loss: 0.1142\n",
            "Epoch: 3, Batch: 1000, Loss: 0.0998\n",
            "Epoch: 3, Batch: 1010, Loss: 0.0968\n",
            "Epoch: 3, Batch: 1020, Loss: 0.1049\n",
            "Epoch: 3, Batch: 1030, Loss: 0.1099\n",
            "Epoch: 3, Batch: 1040, Loss: 0.1186\n",
            "Epoch: 3, Batch: 1050, Loss: 0.1058\n",
            "Epoch: 3, Batch: 1060, Loss: 0.1170\n",
            "Epoch: 3, Batch: 1070, Loss: 0.0980\n",
            "Epoch: 3, Batch: 1080, Loss: 0.0980\n",
            "Epoch: 3, Batch: 1090, Loss: 0.1175\n",
            "Epoch: 3, Batch: 1100, Loss: 0.1236\n",
            "Epoch: 3, Batch: 1110, Loss: 0.1049\n",
            "Epoch: 3, Batch: 1120, Loss: 0.1082\n",
            "Epoch: 3, Batch: 1130, Loss: 0.1104\n",
            "Epoch: 3, Batch: 1140, Loss: 0.0969\n",
            "Epoch: 3, Batch: 1150, Loss: 0.1002\n",
            "Epoch: 3, Batch: 1160, Loss: 0.1125\n",
            "Epoch: 3, Batch: 1170, Loss: 0.1042\n",
            "Epoch: 3, Batch: 1180, Loss: 0.1037\n",
            "Epoch: 3, Batch: 1190, Loss: 0.1072\n",
            "Epoch: 3, Batch: 1200, Loss: 0.1110\n",
            "Epoch: 3, Batch: 1210, Loss: 0.1226\n",
            "Epoch: 3, Batch: 1220, Loss: 0.1057\n",
            "Epoch: 3, Batch: 1230, Loss: 0.0931\n",
            "Epoch: 3, Batch: 1240, Loss: 0.0987\n",
            "Epoch: 3, Batch: 1250, Loss: 0.1027\n",
            "Epoch: 3, Batch: 1260, Loss: 0.0852\n",
            "Epoch: 3, Batch: 1270, Loss: 0.1038\n",
            "Epoch: 3, Batch: 1280, Loss: 0.1073\n",
            "Epoch: 3, Batch: 1290, Loss: 0.1039\n",
            "Epoch: 3, Batch: 1300, Loss: 0.1173\n",
            "Epoch: 3, Batch: 1310, Loss: 0.1081\n",
            "Epoch: 3, Batch: 1320, Loss: 0.1027\n",
            "Epoch: 3, Batch: 1330, Loss: 0.0957\n",
            "Epoch: 3, Batch: 1340, Loss: 0.1037\n",
            "Epoch: 3, Batch: 1350, Loss: 0.0976\n",
            "Epoch: 3, Batch: 1360, Loss: 0.1141\n",
            "Epoch: 3, Batch: 1370, Loss: 0.0938\n",
            "Epoch: 3, Batch: 1380, Loss: 0.0833\n",
            "Epoch: 3, Batch: 1390, Loss: 0.0954\n",
            "Epoch: 3, Batch: 1400, Loss: 0.0808\n",
            "Epoch: 3, Batch: 1410, Loss: 0.0928\n",
            "Epoch: 3, Batch: 1420, Loss: 0.0992\n",
            "Epoch: 3, Batch: 1430, Loss: 0.0864\n",
            "Epoch: 3, Batch: 1440, Loss: 0.0871\n",
            "Epoch: 3, Batch: 1450, Loss: 0.1025\n",
            "Epoch: 3, Train Loss: 0.1281, Val Loss: 0.0989\n",
            "Epoch: 4, Batch: 0, Loss: 0.0885\n",
            "Epoch: 4, Batch: 10, Loss: 0.0736\n",
            "Epoch: 4, Batch: 20, Loss: 0.0949\n",
            "Epoch: 4, Batch: 30, Loss: 0.0754\n",
            "Epoch: 4, Batch: 40, Loss: 0.1115\n",
            "Epoch: 4, Batch: 50, Loss: 0.0797\n",
            "Epoch: 4, Batch: 60, Loss: 0.0874\n",
            "Epoch: 4, Batch: 70, Loss: 0.0856\n",
            "Epoch: 4, Batch: 80, Loss: 0.0866\n",
            "Epoch: 4, Batch: 90, Loss: 0.0828\n",
            "Epoch: 4, Batch: 100, Loss: 0.0730\n",
            "Epoch: 4, Batch: 110, Loss: 0.0775\n",
            "Epoch: 4, Batch: 120, Loss: 0.0948\n",
            "Epoch: 4, Batch: 130, Loss: 0.0872\n",
            "Epoch: 4, Batch: 140, Loss: 0.0854\n",
            "Epoch: 4, Batch: 150, Loss: 0.0895\n",
            "Epoch: 4, Batch: 160, Loss: 0.0978\n",
            "Epoch: 4, Batch: 170, Loss: 0.0878\n",
            "Epoch: 4, Batch: 180, Loss: 0.0981\n",
            "Epoch: 4, Batch: 190, Loss: 0.0909\n",
            "Epoch: 4, Batch: 200, Loss: 0.0799\n",
            "Epoch: 4, Batch: 210, Loss: 0.0781\n",
            "Epoch: 4, Batch: 220, Loss: 0.0854\n",
            "Epoch: 4, Batch: 230, Loss: 0.0829\n",
            "Epoch: 4, Batch: 240, Loss: 0.0805\n",
            "Epoch: 4, Batch: 250, Loss: 0.0781\n",
            "Epoch: 4, Batch: 260, Loss: 0.0851\n",
            "Epoch: 4, Batch: 270, Loss: 0.0852\n",
            "Epoch: 4, Batch: 280, Loss: 0.0810\n",
            "Epoch: 4, Batch: 290, Loss: 0.0925\n",
            "Epoch: 4, Batch: 300, Loss: 0.1079\n",
            "Epoch: 4, Batch: 310, Loss: 0.0952\n",
            "Epoch: 4, Batch: 320, Loss: 0.0793\n",
            "Epoch: 4, Batch: 330, Loss: 0.1176\n",
            "Epoch: 4, Batch: 340, Loss: 0.0826\n",
            "Epoch: 4, Batch: 350, Loss: 0.0881\n",
            "Epoch: 4, Batch: 360, Loss: 0.0981\n",
            "Epoch: 4, Batch: 370, Loss: 0.0911\n",
            "Epoch: 4, Batch: 380, Loss: 0.0802\n",
            "Epoch: 4, Batch: 390, Loss: 0.0805\n",
            "Epoch: 4, Batch: 400, Loss: 0.0809\n",
            "Epoch: 4, Batch: 410, Loss: 0.0858\n",
            "Epoch: 4, Batch: 420, Loss: 0.0785\n",
            "Epoch: 4, Batch: 430, Loss: 0.0774\n",
            "Epoch: 4, Batch: 440, Loss: 0.0916\n",
            "Epoch: 4, Batch: 450, Loss: 0.0775\n",
            "Epoch: 4, Batch: 460, Loss: 0.0873\n",
            "Epoch: 4, Batch: 470, Loss: 0.0732\n",
            "Epoch: 4, Batch: 480, Loss: 0.0813\n",
            "Epoch: 4, Batch: 490, Loss: 0.0806\n",
            "Epoch: 4, Batch: 500, Loss: 0.0894\n",
            "Epoch: 4, Batch: 510, Loss: 0.1033\n",
            "Epoch: 4, Batch: 520, Loss: 0.0838\n",
            "Epoch: 4, Batch: 530, Loss: 0.0801\n",
            "Epoch: 4, Batch: 540, Loss: 0.0860\n",
            "Epoch: 4, Batch: 550, Loss: 0.0812\n",
            "Epoch: 4, Batch: 560, Loss: 0.0671\n",
            "Epoch: 4, Batch: 570, Loss: 0.0701\n",
            "Epoch: 4, Batch: 580, Loss: 0.0971\n",
            "Epoch: 4, Batch: 590, Loss: 0.0824\n",
            "Epoch: 4, Batch: 600, Loss: 0.0752\n",
            "Epoch: 4, Batch: 610, Loss: 0.0824\n",
            "Epoch: 4, Batch: 620, Loss: 0.0781\n",
            "Epoch: 4, Batch: 630, Loss: 0.0860\n",
            "Epoch: 4, Batch: 640, Loss: 0.0900\n",
            "Epoch: 4, Batch: 650, Loss: 0.0988\n",
            "Epoch: 4, Batch: 660, Loss: 0.0708\n",
            "Epoch: 4, Batch: 670, Loss: 0.0697\n",
            "Epoch: 4, Batch: 680, Loss: 0.0821\n",
            "Epoch: 4, Batch: 690, Loss: 0.0980\n",
            "Epoch: 4, Batch: 700, Loss: 0.0722\n",
            "Epoch: 4, Batch: 710, Loss: 0.0811\n",
            "Epoch: 4, Batch: 720, Loss: 0.0793\n",
            "Epoch: 4, Batch: 730, Loss: 0.0833\n",
            "Epoch: 4, Batch: 740, Loss: 0.0826\n",
            "Epoch: 4, Batch: 750, Loss: 0.0762\n",
            "Epoch: 4, Batch: 760, Loss: 0.0822\n",
            "Epoch: 4, Batch: 770, Loss: 0.0608\n",
            "Epoch: 4, Batch: 780, Loss: 0.0793\n",
            "Epoch: 4, Batch: 790, Loss: 0.0657\n",
            "Epoch: 4, Batch: 800, Loss: 0.0765\n",
            "Epoch: 4, Batch: 810, Loss: 0.0876\n",
            "Epoch: 4, Batch: 820, Loss: 0.0833\n",
            "Epoch: 4, Batch: 830, Loss: 0.0769\n",
            "Epoch: 4, Batch: 840, Loss: 0.0859\n",
            "Epoch: 4, Batch: 850, Loss: 0.0862\n",
            "Epoch: 4, Batch: 860, Loss: 0.0944\n",
            "Epoch: 4, Batch: 870, Loss: 0.0792\n",
            "Epoch: 4, Batch: 880, Loss: 0.0839\n",
            "Epoch: 4, Batch: 890, Loss: 0.0804\n",
            "Epoch: 4, Batch: 900, Loss: 0.0928\n",
            "Epoch: 4, Batch: 910, Loss: 0.0738\n",
            "Epoch: 4, Batch: 920, Loss: 0.0720\n",
            "Epoch: 4, Batch: 930, Loss: 0.0627\n",
            "Epoch: 4, Batch: 940, Loss: 0.0729\n",
            "Epoch: 4, Batch: 950, Loss: 0.0818\n",
            "Epoch: 4, Batch: 960, Loss: 0.0794\n",
            "Epoch: 4, Batch: 970, Loss: 0.0932\n",
            "Epoch: 4, Batch: 980, Loss: 0.0621\n",
            "Epoch: 4, Batch: 990, Loss: 0.0781\n",
            "Epoch: 4, Batch: 1000, Loss: 0.0687\n",
            "Epoch: 4, Batch: 1010, Loss: 0.0722\n",
            "Epoch: 4, Batch: 1020, Loss: 0.0844\n",
            "Epoch: 4, Batch: 1030, Loss: 0.0721\n",
            "Epoch: 4, Batch: 1040, Loss: 0.0713\n",
            "Epoch: 4, Batch: 1050, Loss: 0.0709\n",
            "Epoch: 4, Batch: 1060, Loss: 0.0661\n",
            "Epoch: 4, Batch: 1070, Loss: 0.0771\n",
            "Epoch: 4, Batch: 1080, Loss: 0.0790\n",
            "Epoch: 4, Batch: 1090, Loss: 0.0739\n",
            "Epoch: 4, Batch: 1100, Loss: 0.0827\n",
            "Epoch: 4, Batch: 1110, Loss: 0.0765\n",
            "Epoch: 4, Batch: 1120, Loss: 0.0814\n",
            "Epoch: 4, Batch: 1130, Loss: 0.0672\n",
            "Epoch: 4, Batch: 1140, Loss: 0.0840\n",
            "Epoch: 4, Batch: 1150, Loss: 0.0580\n",
            "Epoch: 4, Batch: 1160, Loss: 0.0843\n",
            "Epoch: 4, Batch: 1170, Loss: 0.0745\n",
            "Epoch: 4, Batch: 1180, Loss: 0.0798\n",
            "Epoch: 4, Batch: 1190, Loss: 0.0743\n",
            "Epoch: 4, Batch: 1200, Loss: 0.0693\n",
            "Epoch: 4, Batch: 1210, Loss: 0.0814\n",
            "Epoch: 4, Batch: 1220, Loss: 0.0779\n",
            "Epoch: 4, Batch: 1230, Loss: 0.0736\n",
            "Epoch: 4, Batch: 1240, Loss: 0.0653\n",
            "Epoch: 4, Batch: 1250, Loss: 0.0693\n",
            "Epoch: 4, Batch: 1260, Loss: 0.0807\n",
            "Epoch: 4, Batch: 1270, Loss: 0.0677\n",
            "Epoch: 4, Batch: 1280, Loss: 0.0759\n",
            "Epoch: 4, Batch: 1290, Loss: 0.0896\n",
            "Epoch: 4, Batch: 1300, Loss: 0.0752\n",
            "Epoch: 4, Batch: 1310, Loss: 0.0717\n",
            "Epoch: 4, Batch: 1320, Loss: 0.0706\n",
            "Epoch: 4, Batch: 1330, Loss: 0.0719\n",
            "Epoch: 4, Batch: 1340, Loss: 0.0667\n",
            "Epoch: 4, Batch: 1350, Loss: 0.0727\n",
            "Epoch: 4, Batch: 1360, Loss: 0.0710\n",
            "Epoch: 4, Batch: 1370, Loss: 0.0722\n",
            "Epoch: 4, Batch: 1380, Loss: 0.0641\n",
            "Epoch: 4, Batch: 1390, Loss: 0.0770\n",
            "Epoch: 4, Batch: 1400, Loss: 0.0768\n",
            "Epoch: 4, Batch: 1410, Loss: 0.0636\n",
            "Epoch: 4, Batch: 1420, Loss: 0.0800\n",
            "Epoch: 4, Batch: 1430, Loss: 0.0743\n",
            "Epoch: 4, Batch: 1440, Loss: 0.0614\n",
            "Epoch: 4, Batch: 1450, Loss: 0.0636\n",
            "Epoch: 4, Train Loss: 0.0808, Val Loss: 0.0726\n",
            "Epoch: 5, Batch: 0, Loss: 0.0584\n",
            "Epoch: 5, Batch: 10, Loss: 0.0779\n",
            "Epoch: 5, Batch: 20, Loss: 0.0773\n",
            "Epoch: 5, Batch: 30, Loss: 0.0752\n",
            "Epoch: 5, Batch: 40, Loss: 0.0771\n",
            "Epoch: 5, Batch: 50, Loss: 0.0718\n",
            "Epoch: 5, Batch: 60, Loss: 0.0675\n",
            "Epoch: 5, Batch: 70, Loss: 0.0590\n",
            "Epoch: 5, Batch: 80, Loss: 0.0732\n",
            "Epoch: 5, Batch: 90, Loss: 0.0684\n",
            "Epoch: 5, Batch: 100, Loss: 0.0663\n",
            "Epoch: 5, Batch: 110, Loss: 0.0774\n",
            "Epoch: 5, Batch: 120, Loss: 0.0913\n",
            "Epoch: 5, Batch: 130, Loss: 0.0738\n",
            "Epoch: 5, Batch: 140, Loss: 0.0657\n",
            "Epoch: 5, Batch: 150, Loss: 0.0748\n",
            "Epoch: 5, Batch: 160, Loss: 0.0569\n",
            "Epoch: 5, Batch: 170, Loss: 0.0828\n",
            "Epoch: 5, Batch: 180, Loss: 0.0759\n",
            "Epoch: 5, Batch: 190, Loss: 0.0604\n",
            "Epoch: 5, Batch: 200, Loss: 0.0713\n",
            "Epoch: 5, Batch: 210, Loss: 0.0723\n",
            "Epoch: 5, Batch: 220, Loss: 0.0653\n",
            "Epoch: 5, Batch: 230, Loss: 0.0762\n",
            "Epoch: 5, Batch: 240, Loss: 0.0671\n",
            "Epoch: 5, Batch: 250, Loss: 0.0685\n",
            "Epoch: 5, Batch: 260, Loss: 0.0675\n",
            "Epoch: 5, Batch: 270, Loss: 0.0787\n",
            "Epoch: 5, Batch: 280, Loss: 0.0752\n",
            "Epoch: 5, Batch: 290, Loss: 0.0711\n",
            "Epoch: 5, Batch: 300, Loss: 0.0802\n",
            "Epoch: 5, Batch: 310, Loss: 0.0681\n",
            "Epoch: 5, Batch: 320, Loss: 0.0784\n",
            "Epoch: 5, Batch: 330, Loss: 0.0622\n",
            "Epoch: 5, Batch: 340, Loss: 0.0635\n",
            "Epoch: 5, Batch: 350, Loss: 0.0796\n",
            "Epoch: 5, Batch: 360, Loss: 0.0791\n",
            "Epoch: 5, Batch: 370, Loss: 0.0621\n",
            "Epoch: 5, Batch: 380, Loss: 0.0632\n",
            "Epoch: 5, Batch: 390, Loss: 0.0650\n",
            "Epoch: 5, Batch: 400, Loss: 0.0626\n",
            "Epoch: 5, Batch: 410, Loss: 0.0697\n",
            "Epoch: 5, Batch: 420, Loss: 0.1000\n",
            "Epoch: 5, Batch: 430, Loss: 0.0539\n",
            "Epoch: 5, Batch: 440, Loss: 0.0723\n",
            "Epoch: 5, Batch: 450, Loss: 0.0622\n",
            "Epoch: 5, Batch: 460, Loss: 0.0679\n",
            "Epoch: 5, Batch: 470, Loss: 0.0692\n",
            "Epoch: 5, Batch: 480, Loss: 0.0756\n",
            "Epoch: 5, Batch: 490, Loss: 0.0659\n",
            "Epoch: 5, Batch: 500, Loss: 0.0668\n",
            "Epoch: 5, Batch: 510, Loss: 0.0727\n",
            "Epoch: 5, Batch: 520, Loss: 0.0826\n",
            "Epoch: 5, Batch: 530, Loss: 0.0532\n",
            "Epoch: 5, Batch: 540, Loss: 0.0674\n",
            "Epoch: 5, Batch: 550, Loss: 0.0520\n",
            "Epoch: 5, Batch: 560, Loss: 0.0662\n",
            "Epoch: 5, Batch: 570, Loss: 0.0677\n",
            "Epoch: 5, Batch: 580, Loss: 0.0701\n",
            "Epoch: 5, Batch: 590, Loss: 0.0600\n",
            "Epoch: 5, Batch: 600, Loss: 0.0719\n",
            "Epoch: 5, Batch: 610, Loss: 0.0710\n",
            "Epoch: 5, Batch: 620, Loss: 0.0625\n",
            "Epoch: 5, Batch: 630, Loss: 0.0554\n",
            "Epoch: 5, Batch: 640, Loss: 0.0660\n",
            "Epoch: 5, Batch: 650, Loss: 0.0604\n",
            "Epoch: 5, Batch: 660, Loss: 0.0571\n",
            "Epoch: 5, Batch: 670, Loss: 0.0622\n",
            "Epoch: 5, Batch: 680, Loss: 0.0629\n",
            "Epoch: 5, Batch: 690, Loss: 0.0910\n",
            "Epoch: 5, Batch: 700, Loss: 0.0574\n",
            "Epoch: 5, Batch: 710, Loss: 0.0580\n",
            "Epoch: 5, Batch: 720, Loss: 0.0570\n",
            "Epoch: 5, Batch: 730, Loss: 0.0573\n",
            "Epoch: 5, Batch: 740, Loss: 0.0711\n",
            "Epoch: 5, Batch: 750, Loss: 0.0703\n",
            "Epoch: 5, Batch: 760, Loss: 0.0666\n",
            "Epoch: 5, Batch: 770, Loss: 0.0623\n",
            "Epoch: 5, Batch: 780, Loss: 0.0613\n",
            "Epoch: 5, Batch: 790, Loss: 0.0731\n",
            "Epoch: 5, Batch: 800, Loss: 0.0686\n",
            "Epoch: 5, Batch: 810, Loss: 0.0772\n",
            "Epoch: 5, Batch: 820, Loss: 0.0802\n",
            "Epoch: 5, Batch: 830, Loss: 0.0587\n",
            "Epoch: 5, Batch: 840, Loss: 0.0610\n",
            "Epoch: 5, Batch: 850, Loss: 0.0715\n",
            "Epoch: 5, Batch: 860, Loss: 0.0647\n",
            "Epoch: 5, Batch: 870, Loss: 0.0707\n",
            "Epoch: 5, Batch: 880, Loss: 0.0736\n",
            "Epoch: 5, Batch: 890, Loss: 0.0646\n",
            "Epoch: 5, Batch: 900, Loss: 0.0577\n",
            "Epoch: 5, Batch: 910, Loss: 0.0576\n",
            "Epoch: 5, Batch: 920, Loss: 0.0547\n",
            "Epoch: 5, Batch: 930, Loss: 0.0645\n",
            "Epoch: 5, Batch: 940, Loss: 0.0584\n",
            "Epoch: 5, Batch: 950, Loss: 0.0601\n",
            "Epoch: 5, Batch: 960, Loss: 0.0787\n",
            "Epoch: 5, Batch: 970, Loss: 0.0753\n",
            "Epoch: 5, Batch: 980, Loss: 0.0583\n",
            "Epoch: 5, Batch: 990, Loss: 0.0520\n",
            "Epoch: 5, Batch: 1000, Loss: 0.0671\n",
            "Epoch: 5, Batch: 1010, Loss: 0.0646\n",
            "Epoch: 5, Batch: 1020, Loss: 0.0633\n",
            "Epoch: 5, Batch: 1030, Loss: 0.0751\n",
            "Epoch: 5, Batch: 1040, Loss: 0.0661\n",
            "Epoch: 5, Batch: 1050, Loss: 0.0684\n",
            "Epoch: 5, Batch: 1060, Loss: 0.0565\n",
            "Epoch: 5, Batch: 1070, Loss: 0.0765\n",
            "Epoch: 5, Batch: 1080, Loss: 0.0562\n",
            "Epoch: 5, Batch: 1090, Loss: 0.0746\n",
            "Epoch: 5, Batch: 1100, Loss: 0.0704\n",
            "Epoch: 5, Batch: 1110, Loss: 0.0667\n",
            "Epoch: 5, Batch: 1120, Loss: 0.0556\n",
            "Epoch: 5, Batch: 1130, Loss: 0.0538\n",
            "Epoch: 5, Batch: 1140, Loss: 0.0635\n",
            "Epoch: 5, Batch: 1150, Loss: 0.0651\n",
            "Epoch: 5, Batch: 1160, Loss: 0.0670\n",
            "Epoch: 5, Batch: 1170, Loss: 0.0808\n",
            "Epoch: 5, Batch: 1180, Loss: 0.0586\n",
            "Epoch: 5, Batch: 1190, Loss: 0.0681\n",
            "Epoch: 5, Batch: 1200, Loss: 0.0574\n",
            "Epoch: 5, Batch: 1210, Loss: 0.0654\n",
            "Epoch: 5, Batch: 1220, Loss: 0.0663\n",
            "Epoch: 5, Batch: 1230, Loss: 0.0726\n",
            "Epoch: 5, Batch: 1240, Loss: 0.0651\n",
            "Epoch: 5, Batch: 1250, Loss: 0.0799\n",
            "Epoch: 5, Batch: 1260, Loss: 0.0680\n",
            "Epoch: 5, Batch: 1270, Loss: 0.0524\n",
            "Epoch: 5, Batch: 1280, Loss: 0.0671\n",
            "Epoch: 5, Batch: 1290, Loss: 0.0602\n",
            "Epoch: 5, Batch: 1300, Loss: 0.0664\n",
            "Epoch: 5, Batch: 1310, Loss: 0.0672\n",
            "Epoch: 5, Batch: 1320, Loss: 0.0588\n",
            "Epoch: 5, Batch: 1330, Loss: 0.0747\n",
            "Epoch: 5, Batch: 1340, Loss: 0.0754\n",
            "Epoch: 5, Batch: 1350, Loss: 0.0858\n",
            "Epoch: 5, Batch: 1360, Loss: 0.0657\n",
            "Epoch: 5, Batch: 1370, Loss: 0.0701\n",
            "Epoch: 5, Batch: 1380, Loss: 0.0554\n",
            "Epoch: 5, Batch: 1390, Loss: 0.0516\n",
            "Epoch: 5, Batch: 1400, Loss: 0.0545\n",
            "Epoch: 5, Batch: 1410, Loss: 0.0797\n",
            "Epoch: 5, Batch: 1420, Loss: 0.0727\n",
            "Epoch: 5, Batch: 1430, Loss: 0.0624\n",
            "Epoch: 5, Batch: 1440, Loss: 0.0708\n",
            "Epoch: 5, Batch: 1450, Loss: 0.0707\n",
            "Epoch: 5, Train Loss: 0.0685, Val Loss: 0.0649\n",
            "Epoch: 6, Batch: 0, Loss: 0.0629\n",
            "Epoch: 6, Batch: 10, Loss: 0.0749\n",
            "Epoch: 6, Batch: 20, Loss: 0.0561\n",
            "Epoch: 6, Batch: 30, Loss: 0.0618\n",
            "Epoch: 6, Batch: 40, Loss: 0.0618\n",
            "Epoch: 6, Batch: 50, Loss: 0.0690\n",
            "Epoch: 6, Batch: 60, Loss: 0.0611\n",
            "Epoch: 6, Batch: 70, Loss: 0.0651\n",
            "Epoch: 6, Batch: 80, Loss: 0.0737\n",
            "Epoch: 6, Batch: 90, Loss: 0.0846\n",
            "Epoch: 6, Batch: 100, Loss: 0.0633\n",
            "Epoch: 6, Batch: 110, Loss: 0.0602\n",
            "Epoch: 6, Batch: 120, Loss: 0.0708\n",
            "Epoch: 6, Batch: 130, Loss: 0.0591\n",
            "Epoch: 6, Batch: 140, Loss: 0.0594\n",
            "Epoch: 6, Batch: 150, Loss: 0.0627\n",
            "Epoch: 6, Batch: 160, Loss: 0.0553\n",
            "Epoch: 6, Batch: 170, Loss: 0.0729\n",
            "Epoch: 6, Batch: 180, Loss: 0.0644\n",
            "Epoch: 6, Batch: 190, Loss: 0.0785\n",
            "Epoch: 6, Batch: 200, Loss: 0.0753\n",
            "Epoch: 6, Batch: 210, Loss: 0.0606\n",
            "Epoch: 6, Batch: 220, Loss: 0.0732\n",
            "Epoch: 6, Batch: 230, Loss: 0.0733\n",
            "Epoch: 6, Batch: 240, Loss: 0.0689\n",
            "Epoch: 6, Batch: 250, Loss: 0.0656\n",
            "Epoch: 6, Batch: 260, Loss: 0.0709\n",
            "Epoch: 6, Batch: 270, Loss: 0.0652\n",
            "Epoch: 6, Batch: 280, Loss: 0.0565\n",
            "Epoch: 6, Batch: 290, Loss: 0.0600\n",
            "Epoch: 6, Batch: 300, Loss: 0.0632\n",
            "Epoch: 6, Batch: 310, Loss: 0.0681\n",
            "Epoch: 6, Batch: 320, Loss: 0.0585\n",
            "Epoch: 6, Batch: 330, Loss: 0.0641\n",
            "Epoch: 6, Batch: 340, Loss: 0.0849\n",
            "Epoch: 6, Batch: 350, Loss: 0.0560\n",
            "Epoch: 6, Batch: 360, Loss: 0.0881\n",
            "Epoch: 6, Batch: 370, Loss: 0.0595\n",
            "Epoch: 6, Batch: 380, Loss: 0.0707\n",
            "Epoch: 6, Batch: 390, Loss: 0.0571\n",
            "Epoch: 6, Batch: 400, Loss: 0.0625\n",
            "Epoch: 6, Batch: 410, Loss: 0.0708\n",
            "Epoch: 6, Batch: 420, Loss: 0.0569\n",
            "Epoch: 6, Batch: 430, Loss: 0.0714\n",
            "Epoch: 6, Batch: 440, Loss: 0.0567\n",
            "Epoch: 6, Batch: 450, Loss: 0.0678\n",
            "Epoch: 6, Batch: 460, Loss: 0.0634\n",
            "Epoch: 6, Batch: 470, Loss: 0.0578\n",
            "Epoch: 6, Batch: 480, Loss: 0.0601\n",
            "Epoch: 6, Batch: 490, Loss: 0.0419\n",
            "Epoch: 6, Batch: 500, Loss: 0.0559\n",
            "Epoch: 6, Batch: 510, Loss: 0.0527\n",
            "Epoch: 6, Batch: 520, Loss: 0.0684\n",
            "Epoch: 6, Batch: 530, Loss: 0.0628\n",
            "Epoch: 6, Batch: 540, Loss: 0.0608\n",
            "Epoch: 6, Batch: 550, Loss: 0.0553\n",
            "Epoch: 6, Batch: 560, Loss: 0.0709\n",
            "Epoch: 6, Batch: 570, Loss: 0.0674\n",
            "Epoch: 6, Batch: 580, Loss: 0.0746\n",
            "Epoch: 6, Batch: 590, Loss: 0.0531\n",
            "Epoch: 6, Batch: 600, Loss: 0.0571\n",
            "Epoch: 6, Batch: 610, Loss: 0.0690\n",
            "Epoch: 6, Batch: 620, Loss: 0.0609\n",
            "Epoch: 6, Batch: 630, Loss: 0.0623\n",
            "Epoch: 6, Batch: 640, Loss: 0.0717\n",
            "Epoch: 6, Batch: 650, Loss: 0.0547\n",
            "Epoch: 6, Batch: 660, Loss: 0.0619\n",
            "Epoch: 6, Batch: 670, Loss: 0.0686\n",
            "Epoch: 6, Batch: 680, Loss: 0.0521\n",
            "Epoch: 6, Batch: 690, Loss: 0.0443\n",
            "Epoch: 6, Batch: 700, Loss: 0.0571\n",
            "Epoch: 6, Batch: 710, Loss: 0.0669\n",
            "Epoch: 6, Batch: 720, Loss: 0.0725\n",
            "Epoch: 6, Batch: 730, Loss: 0.0622\n",
            "Epoch: 6, Batch: 740, Loss: 0.0636\n",
            "Epoch: 6, Batch: 750, Loss: 0.0564\n",
            "Epoch: 6, Batch: 760, Loss: 0.0651\n",
            "Epoch: 6, Batch: 770, Loss: 0.0362\n",
            "Epoch: 6, Batch: 780, Loss: 0.0743\n",
            "Epoch: 6, Batch: 790, Loss: 0.0602\n",
            "Epoch: 6, Batch: 800, Loss: 0.0584\n",
            "Epoch: 6, Batch: 810, Loss: 0.0575\n",
            "Epoch: 6, Batch: 820, Loss: 0.0629\n",
            "Epoch: 6, Batch: 830, Loss: 0.0612\n",
            "Epoch: 6, Batch: 840, Loss: 0.0526\n",
            "Epoch: 6, Batch: 850, Loss: 0.0664\n",
            "Epoch: 6, Batch: 860, Loss: 0.0533\n",
            "Epoch: 6, Batch: 870, Loss: 0.0707\n",
            "Epoch: 6, Batch: 880, Loss: 0.0513\n",
            "Epoch: 6, Batch: 890, Loss: 0.0610\n",
            "Epoch: 6, Batch: 900, Loss: 0.0609\n",
            "Epoch: 6, Batch: 910, Loss: 0.0601\n",
            "Epoch: 6, Batch: 920, Loss: 0.0412\n",
            "Epoch: 6, Batch: 930, Loss: 0.0541\n",
            "Epoch: 6, Batch: 940, Loss: 0.0683\n",
            "Epoch: 6, Batch: 950, Loss: 0.0632\n",
            "Epoch: 6, Batch: 960, Loss: 0.0610\n",
            "Epoch: 6, Batch: 970, Loss: 0.0535\n",
            "Epoch: 6, Batch: 980, Loss: 0.0718\n",
            "Epoch: 6, Batch: 990, Loss: 0.0647\n",
            "Epoch: 6, Batch: 1000, Loss: 0.0443\n",
            "Epoch: 6, Batch: 1010, Loss: 0.0596\n",
            "Epoch: 6, Batch: 1020, Loss: 0.0657\n",
            "Epoch: 6, Batch: 1030, Loss: 0.0610\n",
            "Epoch: 6, Batch: 1040, Loss: 0.0591\n",
            "Epoch: 6, Batch: 1050, Loss: 0.0658\n",
            "Epoch: 6, Batch: 1060, Loss: 0.0638\n",
            "Epoch: 6, Batch: 1070, Loss: 0.0759\n",
            "Epoch: 6, Batch: 1080, Loss: 0.0626\n",
            "Epoch: 6, Batch: 1090, Loss: 0.0550\n",
            "Epoch: 6, Batch: 1100, Loss: 0.0548\n",
            "Epoch: 6, Batch: 1110, Loss: 0.0643\n",
            "Epoch: 6, Batch: 1120, Loss: 0.0607\n",
            "Epoch: 6, Batch: 1130, Loss: 0.0580\n",
            "Epoch: 6, Batch: 1140, Loss: 0.0570\n",
            "Epoch: 6, Batch: 1150, Loss: 0.0680\n",
            "Epoch: 6, Batch: 1160, Loss: 0.0803\n",
            "Epoch: 6, Batch: 1170, Loss: 0.0487\n",
            "Epoch: 6, Batch: 1180, Loss: 0.0732\n",
            "Epoch: 6, Batch: 1190, Loss: 0.0625\n",
            "Epoch: 6, Batch: 1200, Loss: 0.0639\n",
            "Epoch: 6, Batch: 1210, Loss: 0.0593\n",
            "Epoch: 6, Batch: 1220, Loss: 0.0525\n",
            "Epoch: 6, Batch: 1230, Loss: 0.0583\n",
            "Epoch: 6, Batch: 1240, Loss: 0.0553\n",
            "Epoch: 6, Batch: 1250, Loss: 0.0595\n",
            "Epoch: 6, Batch: 1260, Loss: 0.0628\n",
            "Epoch: 6, Batch: 1270, Loss: 0.0587\n",
            "Epoch: 6, Batch: 1280, Loss: 0.0608\n",
            "Epoch: 6, Batch: 1290, Loss: 0.0591\n",
            "Epoch: 6, Batch: 1300, Loss: 0.0641\n",
            "Epoch: 6, Batch: 1310, Loss: 0.0715\n",
            "Epoch: 6, Batch: 1320, Loss: 0.0634\n",
            "Epoch: 6, Batch: 1330, Loss: 0.0609\n",
            "Epoch: 6, Batch: 1340, Loss: 0.0484\n",
            "Epoch: 6, Batch: 1350, Loss: 0.0498\n",
            "Epoch: 6, Batch: 1360, Loss: 0.0549\n",
            "Epoch: 6, Batch: 1370, Loss: 0.0560\n",
            "Epoch: 6, Batch: 1380, Loss: 0.0550\n",
            "Epoch: 6, Batch: 1390, Loss: 0.0639\n",
            "Epoch: 6, Batch: 1400, Loss: 0.0781\n",
            "Epoch: 6, Batch: 1410, Loss: 0.0576\n",
            "Epoch: 6, Batch: 1420, Loss: 0.0443\n",
            "Epoch: 6, Batch: 1430, Loss: 0.0578\n",
            "Epoch: 6, Batch: 1440, Loss: 0.0616\n",
            "Epoch: 6, Batch: 1450, Loss: 0.0627\n",
            "Epoch: 6, Train Loss: 0.0623, Val Loss: 0.0637\n",
            "Epoch: 7, Batch: 0, Loss: 0.0650\n",
            "Epoch: 7, Batch: 10, Loss: 0.0556\n",
            "Epoch: 7, Batch: 20, Loss: 0.0591\n",
            "Epoch: 7, Batch: 30, Loss: 0.0534\n",
            "Epoch: 7, Batch: 40, Loss: 0.0555\n",
            "Epoch: 7, Batch: 50, Loss: 0.0611\n",
            "Epoch: 7, Batch: 60, Loss: 0.0808\n",
            "Epoch: 7, Batch: 70, Loss: 0.0603\n",
            "Epoch: 7, Batch: 80, Loss: 0.0487\n",
            "Epoch: 7, Batch: 90, Loss: 0.0520\n",
            "Epoch: 7, Batch: 100, Loss: 0.0570\n",
            "Epoch: 7, Batch: 110, Loss: 0.0589\n",
            "Epoch: 7, Batch: 120, Loss: 0.0543\n",
            "Epoch: 7, Batch: 130, Loss: 0.0516\n",
            "Epoch: 7, Batch: 140, Loss: 0.0485\n",
            "Epoch: 7, Batch: 150, Loss: 0.0515\n",
            "Epoch: 7, Batch: 160, Loss: 0.0489\n",
            "Epoch: 7, Batch: 170, Loss: 0.0664\n",
            "Epoch: 7, Batch: 180, Loss: 0.0530\n",
            "Epoch: 7, Batch: 190, Loss: 0.0516\n",
            "Epoch: 7, Batch: 200, Loss: 0.0567\n",
            "Epoch: 7, Batch: 210, Loss: 0.0520\n",
            "Epoch: 7, Batch: 220, Loss: 0.0596\n",
            "Epoch: 7, Batch: 230, Loss: 0.0615\n",
            "Epoch: 7, Batch: 240, Loss: 0.0579\n",
            "Epoch: 7, Batch: 250, Loss: 0.0720\n",
            "Epoch: 7, Batch: 260, Loss: 0.0576\n",
            "Epoch: 7, Batch: 270, Loss: 0.0832\n",
            "Epoch: 7, Batch: 280, Loss: 0.0657\n",
            "Epoch: 7, Batch: 290, Loss: 0.0538\n",
            "Epoch: 7, Batch: 300, Loss: 0.0571\n",
            "Epoch: 7, Batch: 310, Loss: 0.0609\n",
            "Epoch: 7, Batch: 320, Loss: 0.0528\n",
            "Epoch: 7, Batch: 330, Loss: 0.0567\n",
            "Epoch: 7, Batch: 340, Loss: 0.0641\n",
            "Epoch: 7, Batch: 350, Loss: 0.0537\n",
            "Epoch: 7, Batch: 360, Loss: 0.0500\n",
            "Epoch: 7, Batch: 370, Loss: 0.0598\n",
            "Epoch: 7, Batch: 380, Loss: 0.0476\n",
            "Epoch: 7, Batch: 390, Loss: 0.0528\n",
            "Epoch: 7, Batch: 400, Loss: 0.0476\n",
            "Epoch: 7, Batch: 410, Loss: 0.0517\n",
            "Epoch: 7, Batch: 420, Loss: 0.0531\n",
            "Epoch: 7, Batch: 430, Loss: 0.0637\n",
            "Epoch: 7, Batch: 440, Loss: 0.0528\n",
            "Epoch: 7, Batch: 450, Loss: 0.0598\n",
            "Epoch: 7, Batch: 460, Loss: 0.0524\n",
            "Epoch: 7, Batch: 470, Loss: 0.0561\n",
            "Epoch: 7, Batch: 480, Loss: 0.0617\n",
            "Epoch: 7, Batch: 490, Loss: 0.0518\n",
            "Epoch: 7, Batch: 500, Loss: 0.0558\n",
            "Epoch: 7, Batch: 510, Loss: 0.0632\n",
            "Epoch: 7, Batch: 520, Loss: 0.0515\n",
            "Epoch: 7, Batch: 530, Loss: 0.0617\n",
            "Epoch: 7, Batch: 540, Loss: 0.0646\n",
            "Epoch: 7, Batch: 550, Loss: 0.0510\n",
            "Epoch: 7, Batch: 560, Loss: 0.0601\n",
            "Epoch: 7, Batch: 570, Loss: 0.0585\n",
            "Epoch: 7, Batch: 580, Loss: 0.0571\n",
            "Epoch: 7, Batch: 590, Loss: 0.0671\n",
            "Epoch: 7, Batch: 600, Loss: 0.0570\n",
            "Epoch: 7, Batch: 610, Loss: 0.0672\n",
            "Epoch: 7, Batch: 620, Loss: 0.0713\n",
            "Epoch: 7, Batch: 630, Loss: 0.0448\n",
            "Epoch: 7, Batch: 640, Loss: 0.0618\n",
            "Epoch: 7, Batch: 650, Loss: 0.0586\n",
            "Epoch: 7, Batch: 660, Loss: 0.0481\n",
            "Epoch: 7, Batch: 670, Loss: 0.0593\n",
            "Epoch: 7, Batch: 680, Loss: 0.0481\n",
            "Epoch: 7, Batch: 690, Loss: 0.0574\n",
            "Epoch: 7, Batch: 700, Loss: 0.0686\n",
            "Epoch: 7, Batch: 710, Loss: 0.0609\n",
            "Epoch: 7, Batch: 720, Loss: 0.0595\n",
            "Epoch: 7, Batch: 730, Loss: 0.0661\n",
            "Epoch: 7, Batch: 740, Loss: 0.0545\n",
            "Epoch: 7, Batch: 750, Loss: 0.0469\n",
            "Epoch: 7, Batch: 760, Loss: 0.0658\n",
            "Epoch: 7, Batch: 770, Loss: 0.0487\n",
            "Epoch: 7, Batch: 780, Loss: 0.0673\n",
            "Epoch: 7, Batch: 790, Loss: 0.0625\n",
            "Epoch: 7, Batch: 800, Loss: 0.0449\n",
            "Epoch: 7, Batch: 810, Loss: 0.0566\n",
            "Epoch: 7, Batch: 820, Loss: 0.0592\n",
            "Epoch: 7, Batch: 830, Loss: 0.0750\n",
            "Epoch: 7, Batch: 840, Loss: 0.0637\n",
            "Epoch: 7, Batch: 850, Loss: 0.0621\n",
            "Epoch: 7, Batch: 860, Loss: 0.0654\n",
            "Epoch: 7, Batch: 870, Loss: 0.0561\n",
            "Epoch: 7, Batch: 880, Loss: 0.0737\n",
            "Epoch: 7, Batch: 890, Loss: 0.0593\n",
            "Epoch: 7, Batch: 900, Loss: 0.0482\n",
            "Epoch: 7, Batch: 910, Loss: 0.0643\n",
            "Epoch: 7, Batch: 920, Loss: 0.0560\n",
            "Epoch: 7, Batch: 930, Loss: 0.0522\n",
            "Epoch: 7, Batch: 940, Loss: 0.0512\n",
            "Epoch: 7, Batch: 950, Loss: 0.0528\n",
            "Epoch: 7, Batch: 960, Loss: 0.0733\n",
            "Epoch: 7, Batch: 970, Loss: 0.0520\n",
            "Epoch: 7, Batch: 980, Loss: 0.0544\n",
            "Epoch: 7, Batch: 990, Loss: 0.0702\n",
            "Epoch: 7, Batch: 1000, Loss: 0.0562\n",
            "Epoch: 7, Batch: 1010, Loss: 0.0474\n",
            "Epoch: 7, Batch: 1020, Loss: 0.0648\n",
            "Epoch: 7, Batch: 1030, Loss: 0.0603\n",
            "Epoch: 7, Batch: 1040, Loss: 0.0604\n",
            "Epoch: 7, Batch: 1050, Loss: 0.0623\n",
            "Epoch: 7, Batch: 1060, Loss: 0.0536\n",
            "Epoch: 7, Batch: 1070, Loss: 0.0651\n",
            "Epoch: 7, Batch: 1080, Loss: 0.0591\n",
            "Epoch: 7, Batch: 1090, Loss: 0.0536\n",
            "Epoch: 7, Batch: 1100, Loss: 0.0735\n",
            "Epoch: 7, Batch: 1110, Loss: 0.0619\n",
            "Epoch: 7, Batch: 1120, Loss: 0.0540\n",
            "Epoch: 7, Batch: 1130, Loss: 0.0605\n",
            "Epoch: 7, Batch: 1140, Loss: 0.0777\n",
            "Epoch: 7, Batch: 1150, Loss: 0.0565\n",
            "Epoch: 7, Batch: 1160, Loss: 0.0489\n",
            "Epoch: 7, Batch: 1170, Loss: 0.0515\n",
            "Epoch: 7, Batch: 1180, Loss: 0.0624\n",
            "Epoch: 7, Batch: 1190, Loss: 0.0486\n",
            "Epoch: 7, Batch: 1200, Loss: 0.0551\n",
            "Epoch: 7, Batch: 1210, Loss: 0.0570\n",
            "Epoch: 7, Batch: 1220, Loss: 0.0714\n",
            "Epoch: 7, Batch: 1230, Loss: 0.0592\n",
            "Epoch: 7, Batch: 1240, Loss: 0.0496\n",
            "Epoch: 7, Batch: 1250, Loss: 0.0551\n",
            "Epoch: 7, Batch: 1260, Loss: 0.0542\n",
            "Epoch: 7, Batch: 1270, Loss: 0.0476\n",
            "Epoch: 7, Batch: 1280, Loss: 0.0527\n",
            "Epoch: 7, Batch: 1290, Loss: 0.0500\n",
            "Epoch: 7, Batch: 1300, Loss: 0.0589\n",
            "Epoch: 7, Batch: 1310, Loss: 0.0584\n",
            "Epoch: 7, Batch: 1320, Loss: 0.0556\n",
            "Epoch: 7, Batch: 1330, Loss: 0.0426\n",
            "Epoch: 7, Batch: 1340, Loss: 0.0512\n",
            "Epoch: 7, Batch: 1350, Loss: 0.0505\n",
            "Epoch: 7, Batch: 1360, Loss: 0.0504\n",
            "Epoch: 7, Batch: 1370, Loss: 0.0580\n",
            "Epoch: 7, Batch: 1380, Loss: 0.0509\n",
            "Epoch: 7, Batch: 1390, Loss: 0.0574\n",
            "Epoch: 7, Batch: 1400, Loss: 0.0518\n",
            "Epoch: 7, Batch: 1410, Loss: 0.0611\n",
            "Epoch: 7, Batch: 1420, Loss: 0.0527\n",
            "Epoch: 7, Batch: 1430, Loss: 0.0570\n",
            "Epoch: 7, Batch: 1440, Loss: 0.0530\n",
            "Epoch: 7, Batch: 1450, Loss: 0.0555\n",
            "Epoch: 7, Train Loss: 0.0577, Val Loss: 0.0597\n",
            "Epoch: 8, Batch: 0, Loss: 0.0484\n",
            "Epoch: 8, Batch: 10, Loss: 0.0618\n",
            "Epoch: 8, Batch: 20, Loss: 0.0592\n",
            "Epoch: 8, Batch: 30, Loss: 0.0514\n",
            "Epoch: 8, Batch: 40, Loss: 0.0433\n",
            "Epoch: 8, Batch: 50, Loss: 0.0549\n",
            "Epoch: 8, Batch: 60, Loss: 0.0558\n",
            "Epoch: 8, Batch: 70, Loss: 0.0588\n",
            "Epoch: 8, Batch: 80, Loss: 0.0539\n",
            "Epoch: 8, Batch: 90, Loss: 0.0586\n",
            "Epoch: 8, Batch: 100, Loss: 0.0660\n",
            "Epoch: 8, Batch: 110, Loss: 0.0587\n",
            "Epoch: 8, Batch: 120, Loss: 0.0496\n",
            "Epoch: 8, Batch: 130, Loss: 0.0475\n",
            "Epoch: 8, Batch: 140, Loss: 0.0542\n",
            "Epoch: 8, Batch: 150, Loss: 0.0531\n",
            "Epoch: 8, Batch: 160, Loss: 0.0590\n",
            "Epoch: 8, Batch: 170, Loss: 0.0442\n",
            "Epoch: 8, Batch: 180, Loss: 0.0609\n",
            "Epoch: 8, Batch: 190, Loss: 0.0514\n",
            "Epoch: 8, Batch: 200, Loss: 0.0549\n",
            "Epoch: 8, Batch: 210, Loss: 0.0506\n",
            "Epoch: 8, Batch: 220, Loss: 0.0638\n",
            "Epoch: 8, Batch: 230, Loss: 0.0660\n",
            "Epoch: 8, Batch: 240, Loss: 0.0568\n",
            "Epoch: 8, Batch: 250, Loss: 0.0492\n",
            "Epoch: 8, Batch: 260, Loss: 0.0577\n",
            "Epoch: 8, Batch: 270, Loss: 0.0604\n",
            "Epoch: 8, Batch: 280, Loss: 0.0495\n",
            "Epoch: 8, Batch: 290, Loss: 0.0476\n",
            "Epoch: 8, Batch: 300, Loss: 0.0506\n",
            "Epoch: 8, Batch: 310, Loss: 0.0434\n",
            "Epoch: 8, Batch: 320, Loss: 0.0655\n",
            "Epoch: 8, Batch: 330, Loss: 0.0518\n",
            "Epoch: 8, Batch: 340, Loss: 0.0521\n",
            "Epoch: 8, Batch: 350, Loss: 0.0675\n",
            "Epoch: 8, Batch: 360, Loss: 0.0589\n",
            "Epoch: 8, Batch: 370, Loss: 0.0480\n",
            "Epoch: 8, Batch: 380, Loss: 0.0482\n",
            "Epoch: 8, Batch: 390, Loss: 0.0577\n",
            "Epoch: 8, Batch: 400, Loss: 0.0470\n",
            "Epoch: 8, Batch: 410, Loss: 0.0518\n",
            "Epoch: 8, Batch: 420, Loss: 0.0484\n",
            "Epoch: 8, Batch: 430, Loss: 0.0461\n",
            "Epoch: 8, Batch: 440, Loss: 0.0620\n",
            "Epoch: 8, Batch: 450, Loss: 0.0574\n",
            "Epoch: 8, Batch: 460, Loss: 0.0584\n",
            "Epoch: 8, Batch: 470, Loss: 0.0598\n",
            "Epoch: 8, Batch: 480, Loss: 0.0581\n",
            "Epoch: 8, Batch: 490, Loss: 0.0510\n",
            "Epoch: 8, Batch: 500, Loss: 0.0538\n",
            "Epoch: 8, Batch: 510, Loss: 0.0531\n",
            "Epoch: 8, Batch: 520, Loss: 0.0563\n",
            "Epoch: 8, Batch: 530, Loss: 0.0486\n",
            "Epoch: 8, Batch: 540, Loss: 0.0500\n",
            "Epoch: 8, Batch: 550, Loss: 0.0586\n",
            "Epoch: 8, Batch: 560, Loss: 0.0690\n",
            "Epoch: 8, Batch: 570, Loss: 0.0525\n",
            "Epoch: 8, Batch: 580, Loss: 0.0527\n",
            "Epoch: 8, Batch: 590, Loss: 0.0486\n",
            "Epoch: 8, Batch: 600, Loss: 0.0549\n",
            "Epoch: 8, Batch: 610, Loss: 0.0513\n",
            "Epoch: 8, Batch: 620, Loss: 0.0503\n",
            "Epoch: 8, Batch: 630, Loss: 0.0715\n",
            "Epoch: 8, Batch: 640, Loss: 0.0647\n",
            "Epoch: 8, Batch: 650, Loss: 0.0576\n",
            "Epoch: 8, Batch: 660, Loss: 0.0763\n",
            "Epoch: 8, Batch: 670, Loss: 0.0563\n",
            "Epoch: 8, Batch: 680, Loss: 0.0475\n",
            "Epoch: 8, Batch: 690, Loss: 0.0630\n",
            "Epoch: 8, Batch: 700, Loss: 0.0595\n",
            "Epoch: 8, Batch: 710, Loss: 0.0473\n",
            "Epoch: 8, Batch: 720, Loss: 0.0525\n",
            "Epoch: 8, Batch: 730, Loss: 0.0649\n",
            "Epoch: 8, Batch: 740, Loss: 0.0573\n",
            "Epoch: 8, Batch: 750, Loss: 0.0594\n",
            "Epoch: 8, Batch: 760, Loss: 0.0604\n",
            "Epoch: 8, Batch: 770, Loss: 0.0538\n",
            "Epoch: 8, Batch: 780, Loss: 0.0670\n",
            "Epoch: 8, Batch: 790, Loss: 0.0538\n",
            "Epoch: 8, Batch: 800, Loss: 0.0586\n",
            "Epoch: 8, Batch: 810, Loss: 0.0482\n",
            "Epoch: 8, Batch: 820, Loss: 0.0526\n",
            "Epoch: 8, Batch: 830, Loss: 0.0479\n",
            "Epoch: 8, Batch: 840, Loss: 0.0554\n",
            "Epoch: 8, Batch: 850, Loss: 0.0518\n",
            "Epoch: 8, Batch: 860, Loss: 0.0461\n",
            "Epoch: 8, Batch: 870, Loss: 0.0515\n",
            "Epoch: 8, Batch: 880, Loss: 0.0599\n",
            "Epoch: 8, Batch: 890, Loss: 0.0594\n",
            "Epoch: 8, Batch: 900, Loss: 0.0519\n",
            "Epoch: 8, Batch: 910, Loss: 0.0548\n",
            "Epoch: 8, Batch: 920, Loss: 0.0502\n",
            "Epoch: 8, Batch: 930, Loss: 0.0620\n",
            "Epoch: 8, Batch: 940, Loss: 0.0582\n",
            "Epoch: 8, Batch: 950, Loss: 0.0482\n",
            "Epoch: 8, Batch: 960, Loss: 0.0443\n",
            "Epoch: 8, Batch: 970, Loss: 0.0490\n",
            "Epoch: 8, Batch: 980, Loss: 0.0535\n",
            "Epoch: 8, Batch: 990, Loss: 0.0547\n",
            "Epoch: 8, Batch: 1000, Loss: 0.0532\n",
            "Epoch: 8, Batch: 1010, Loss: 0.0589\n",
            "Epoch: 8, Batch: 1020, Loss: 0.0516\n",
            "Epoch: 8, Batch: 1030, Loss: 0.0492\n",
            "Epoch: 8, Batch: 1040, Loss: 0.0566\n",
            "Epoch: 8, Batch: 1050, Loss: 0.0488\n",
            "Epoch: 8, Batch: 1060, Loss: 0.0567\n",
            "Epoch: 8, Batch: 1070, Loss: 0.0502\n",
            "Epoch: 8, Batch: 1080, Loss: 0.0462\n",
            "Epoch: 8, Batch: 1090, Loss: 0.0570\n",
            "Epoch: 8, Batch: 1100, Loss: 0.0511\n",
            "Epoch: 8, Batch: 1110, Loss: 0.0640\n",
            "Epoch: 8, Batch: 1120, Loss: 0.0450\n",
            "Epoch: 8, Batch: 1130, Loss: 0.0561\n",
            "Epoch: 8, Batch: 1140, Loss: 0.0499\n",
            "Epoch: 8, Batch: 1150, Loss: 0.0515\n",
            "Epoch: 8, Batch: 1160, Loss: 0.0459\n",
            "Epoch: 8, Batch: 1170, Loss: 0.0509\n",
            "Epoch: 8, Batch: 1180, Loss: 0.0532\n",
            "Epoch: 8, Batch: 1190, Loss: 0.0527\n",
            "Epoch: 8, Batch: 1200, Loss: 0.0432\n",
            "Epoch: 8, Batch: 1210, Loss: 0.0533\n",
            "Epoch: 8, Batch: 1220, Loss: 0.0471\n",
            "Epoch: 8, Batch: 1230, Loss: 0.0489\n",
            "Epoch: 8, Batch: 1240, Loss: 0.0467\n",
            "Epoch: 8, Batch: 1250, Loss: 0.0524\n",
            "Epoch: 8, Batch: 1260, Loss: 0.0551\n",
            "Epoch: 8, Batch: 1270, Loss: 0.0550\n",
            "Epoch: 8, Batch: 1280, Loss: 0.0491\n",
            "Epoch: 8, Batch: 1290, Loss: 0.0610\n",
            "Epoch: 8, Batch: 1300, Loss: 0.0605\n",
            "Epoch: 8, Batch: 1310, Loss: 0.0510\n",
            "Epoch: 8, Batch: 1320, Loss: 0.0557\n",
            "Epoch: 8, Batch: 1330, Loss: 0.0641\n",
            "Epoch: 8, Batch: 1340, Loss: 0.0439\n",
            "Epoch: 8, Batch: 1350, Loss: 0.0454\n",
            "Epoch: 8, Batch: 1360, Loss: 0.0430\n",
            "Epoch: 8, Batch: 1370, Loss: 0.0566\n",
            "Epoch: 8, Batch: 1380, Loss: 0.0421\n",
            "Epoch: 8, Batch: 1390, Loss: 0.0464\n",
            "Epoch: 8, Batch: 1400, Loss: 0.0672\n",
            "Epoch: 8, Batch: 1410, Loss: 0.0369\n",
            "Epoch: 8, Batch: 1420, Loss: 0.0610\n",
            "Epoch: 8, Batch: 1430, Loss: 0.0466\n",
            "Epoch: 8, Batch: 1440, Loss: 0.0453\n",
            "Epoch: 8, Batch: 1450, Loss: 0.0376\n",
            "Epoch: 8, Train Loss: 0.0539, Val Loss: 0.0549\n",
            "Epoch: 9, Batch: 0, Loss: 0.0542\n",
            "Epoch: 9, Batch: 10, Loss: 0.0542\n",
            "Epoch: 9, Batch: 20, Loss: 0.0473\n",
            "Epoch: 9, Batch: 30, Loss: 0.0521\n",
            "Epoch: 9, Batch: 40, Loss: 0.0393\n",
            "Epoch: 9, Batch: 50, Loss: 0.0495\n",
            "Epoch: 9, Batch: 60, Loss: 0.0445\n",
            "Epoch: 9, Batch: 70, Loss: 0.0634\n",
            "Epoch: 9, Batch: 80, Loss: 0.0590\n",
            "Epoch: 9, Batch: 90, Loss: 0.0548\n",
            "Epoch: 9, Batch: 100, Loss: 0.0407\n",
            "Epoch: 9, Batch: 110, Loss: 0.0555\n",
            "Epoch: 9, Batch: 120, Loss: 0.0488\n",
            "Epoch: 9, Batch: 130, Loss: 0.0527\n",
            "Epoch: 9, Batch: 140, Loss: 0.0446\n",
            "Epoch: 9, Batch: 150, Loss: 0.0433\n",
            "Epoch: 9, Batch: 160, Loss: 0.0500\n",
            "Epoch: 9, Batch: 170, Loss: 0.0586\n",
            "Epoch: 9, Batch: 180, Loss: 0.0482\n",
            "Epoch: 9, Batch: 190, Loss: 0.0465\n",
            "Epoch: 9, Batch: 200, Loss: 0.0563\n",
            "Epoch: 9, Batch: 210, Loss: 0.0534\n",
            "Epoch: 9, Batch: 220, Loss: 0.0589\n",
            "Epoch: 9, Batch: 230, Loss: 0.0622\n",
            "Epoch: 9, Batch: 240, Loss: 0.0485\n",
            "Epoch: 9, Batch: 250, Loss: 0.0635\n",
            "Epoch: 9, Batch: 260, Loss: 0.0525\n",
            "Epoch: 9, Batch: 270, Loss: 0.0506\n",
            "Epoch: 9, Batch: 280, Loss: 0.0401\n",
            "Epoch: 9, Batch: 290, Loss: 0.0543\n",
            "Epoch: 9, Batch: 300, Loss: 0.0372\n",
            "Epoch: 9, Batch: 310, Loss: 0.0586\n",
            "Epoch: 9, Batch: 320, Loss: 0.0506\n",
            "Epoch: 9, Batch: 330, Loss: 0.0560\n",
            "Epoch: 9, Batch: 340, Loss: 0.0606\n",
            "Epoch: 9, Batch: 350, Loss: 0.0474\n",
            "Epoch: 9, Batch: 360, Loss: 0.0510\n",
            "Epoch: 9, Batch: 370, Loss: 0.0582\n",
            "Epoch: 9, Batch: 380, Loss: 0.0478\n",
            "Epoch: 9, Batch: 390, Loss: 0.0502\n",
            "Epoch: 9, Batch: 400, Loss: 0.0471\n",
            "Epoch: 9, Batch: 410, Loss: 0.0520\n",
            "Epoch: 9, Batch: 420, Loss: 0.0518\n",
            "Epoch: 9, Batch: 430, Loss: 0.0419\n",
            "Epoch: 9, Batch: 440, Loss: 0.0397\n",
            "Epoch: 9, Batch: 450, Loss: 0.0480\n",
            "Epoch: 9, Batch: 460, Loss: 0.0438\n",
            "Epoch: 9, Batch: 470, Loss: 0.0468\n",
            "Epoch: 9, Batch: 480, Loss: 0.0393\n",
            "Epoch: 9, Batch: 490, Loss: 0.0446\n",
            "Epoch: 9, Batch: 500, Loss: 0.0487\n",
            "Epoch: 9, Batch: 510, Loss: 0.0515\n",
            "Epoch: 9, Batch: 520, Loss: 0.0458\n",
            "Epoch: 9, Batch: 530, Loss: 0.0445\n",
            "Epoch: 9, Batch: 540, Loss: 0.0510\n",
            "Epoch: 9, Batch: 550, Loss: 0.0427\n",
            "Epoch: 9, Batch: 560, Loss: 0.0584\n",
            "Epoch: 9, Batch: 570, Loss: 0.0419\n",
            "Epoch: 9, Batch: 580, Loss: 0.0587\n",
            "Epoch: 9, Batch: 590, Loss: 0.0570\n",
            "Epoch: 9, Batch: 600, Loss: 0.0470\n",
            "Epoch: 9, Batch: 610, Loss: 0.0526\n",
            "Epoch: 9, Batch: 620, Loss: 0.0516\n",
            "Epoch: 9, Batch: 630, Loss: 0.0502\n",
            "Epoch: 9, Batch: 640, Loss: 0.0471\n",
            "Epoch: 9, Batch: 650, Loss: 0.0600\n",
            "Epoch: 9, Batch: 660, Loss: 0.0434\n",
            "Epoch: 9, Batch: 670, Loss: 0.0552\n",
            "Epoch: 9, Batch: 680, Loss: 0.0459\n",
            "Epoch: 9, Batch: 690, Loss: 0.0673\n",
            "Epoch: 9, Batch: 700, Loss: 0.0512\n",
            "Epoch: 9, Batch: 710, Loss: 0.0458\n",
            "Epoch: 9, Batch: 720, Loss: 0.0505\n",
            "Epoch: 9, Batch: 730, Loss: 0.0502\n",
            "Epoch: 9, Batch: 740, Loss: 0.0601\n",
            "Epoch: 9, Batch: 750, Loss: 0.0684\n",
            "Epoch: 9, Batch: 760, Loss: 0.0485\n",
            "Epoch: 9, Batch: 770, Loss: 0.0500\n",
            "Epoch: 9, Batch: 780, Loss: 0.0647\n",
            "Epoch: 9, Batch: 790, Loss: 0.0533\n",
            "Epoch: 9, Batch: 800, Loss: 0.0429\n",
            "Epoch: 9, Batch: 810, Loss: 0.0452\n",
            "Epoch: 9, Batch: 820, Loss: 0.0524\n",
            "Epoch: 9, Batch: 830, Loss: 0.0462\n",
            "Epoch: 9, Batch: 840, Loss: 0.0439\n",
            "Epoch: 9, Batch: 850, Loss: 0.0405\n",
            "Epoch: 9, Batch: 860, Loss: 0.0470\n",
            "Epoch: 9, Batch: 870, Loss: 0.0485\n",
            "Epoch: 9, Batch: 880, Loss: 0.0462\n",
            "Epoch: 9, Batch: 890, Loss: 0.0477\n",
            "Epoch: 9, Batch: 900, Loss: 0.0519\n",
            "Epoch: 9, Batch: 910, Loss: 0.0614\n",
            "Epoch: 9, Batch: 920, Loss: 0.0432\n",
            "Epoch: 9, Batch: 930, Loss: 0.0466\n",
            "Epoch: 9, Batch: 940, Loss: 0.0411\n",
            "Epoch: 9, Batch: 950, Loss: 0.0519\n",
            "Epoch: 9, Batch: 960, Loss: 0.0506\n",
            "Epoch: 9, Batch: 970, Loss: 0.0468\n",
            "Epoch: 9, Batch: 980, Loss: 0.0598\n",
            "Epoch: 9, Batch: 990, Loss: 0.0565\n",
            "Epoch: 9, Batch: 1000, Loss: 0.0395\n",
            "Epoch: 9, Batch: 1010, Loss: 0.0393\n",
            "Epoch: 9, Batch: 1020, Loss: 0.0525\n",
            "Epoch: 9, Batch: 1030, Loss: 0.0395\n",
            "Epoch: 9, Batch: 1040, Loss: 0.0523\n",
            "Epoch: 9, Batch: 1050, Loss: 0.0479\n",
            "Epoch: 9, Batch: 1060, Loss: 0.0588\n",
            "Epoch: 9, Batch: 1070, Loss: 0.0630\n",
            "Epoch: 9, Batch: 1080, Loss: 0.0496\n",
            "Epoch: 9, Batch: 1090, Loss: 0.0439\n",
            "Epoch: 9, Batch: 1100, Loss: 0.0533\n",
            "Epoch: 9, Batch: 1110, Loss: 0.0547\n",
            "Epoch: 9, Batch: 1120, Loss: 0.0566\n",
            "Epoch: 9, Batch: 1130, Loss: 0.0485\n",
            "Epoch: 9, Batch: 1140, Loss: 0.0430\n",
            "Epoch: 9, Batch: 1150, Loss: 0.0469\n",
            "Epoch: 9, Batch: 1160, Loss: 0.0567\n",
            "Epoch: 9, Batch: 1170, Loss: 0.0360\n",
            "Epoch: 9, Batch: 1180, Loss: 0.0431\n",
            "Epoch: 9, Batch: 1190, Loss: 0.0496\n",
            "Epoch: 9, Batch: 1200, Loss: 0.0506\n",
            "Epoch: 9, Batch: 1210, Loss: 0.0548\n",
            "Epoch: 9, Batch: 1220, Loss: 0.0511\n",
            "Epoch: 9, Batch: 1230, Loss: 0.0506\n",
            "Epoch: 9, Batch: 1240, Loss: 0.0520\n",
            "Epoch: 9, Batch: 1250, Loss: 0.0602\n",
            "Epoch: 9, Batch: 1260, Loss: 0.0492\n",
            "Epoch: 9, Batch: 1270, Loss: 0.0447\n",
            "Epoch: 9, Batch: 1280, Loss: 0.0394\n",
            "Epoch: 9, Batch: 1290, Loss: 0.0471\n",
            "Epoch: 9, Batch: 1300, Loss: 0.0487\n",
            "Epoch: 9, Batch: 1310, Loss: 0.0522\n",
            "Epoch: 9, Batch: 1320, Loss: 0.0492\n",
            "Epoch: 9, Batch: 1330, Loss: 0.0593\n",
            "Epoch: 9, Batch: 1340, Loss: 0.0430\n",
            "Epoch: 9, Batch: 1350, Loss: 0.0618\n",
            "Epoch: 9, Batch: 1360, Loss: 0.0405\n",
            "Epoch: 9, Batch: 1370, Loss: 0.0559\n",
            "Epoch: 9, Batch: 1380, Loss: 0.0541\n",
            "Epoch: 9, Batch: 1390, Loss: 0.0456\n",
            "Epoch: 9, Batch: 1400, Loss: 0.0547\n",
            "Epoch: 9, Batch: 1410, Loss: 0.0449\n",
            "Epoch: 9, Batch: 1420, Loss: 0.0524\n",
            "Epoch: 9, Batch: 1430, Loss: 0.0497\n",
            "Epoch: 9, Batch: 1440, Loss: 0.0443\n",
            "Epoch: 9, Batch: 1450, Loss: 0.0507\n",
            "Epoch: 9, Train Loss: 0.0503, Val Loss: 0.0546\n",
            "Epoch: 10, Batch: 0, Loss: 0.0439\n",
            "Epoch: 10, Batch: 10, Loss: 0.0491\n",
            "Epoch: 10, Batch: 20, Loss: 0.0508\n",
            "Epoch: 10, Batch: 30, Loss: 0.0391\n",
            "Epoch: 10, Batch: 40, Loss: 0.0461\n",
            "Epoch: 10, Batch: 50, Loss: 0.0524\n",
            "Epoch: 10, Batch: 60, Loss: 0.0415\n",
            "Epoch: 10, Batch: 70, Loss: 0.0414\n",
            "Epoch: 10, Batch: 80, Loss: 0.0504\n",
            "Epoch: 10, Batch: 90, Loss: 0.0405\n",
            "Epoch: 10, Batch: 100, Loss: 0.0414\n",
            "Epoch: 10, Batch: 110, Loss: 0.0426\n",
            "Epoch: 10, Batch: 120, Loss: 0.0442\n",
            "Epoch: 10, Batch: 130, Loss: 0.0558\n",
            "Epoch: 10, Batch: 140, Loss: 0.0471\n",
            "Epoch: 10, Batch: 150, Loss: 0.0426\n",
            "Epoch: 10, Batch: 160, Loss: 0.0433\n",
            "Epoch: 10, Batch: 170, Loss: 0.0535\n",
            "Epoch: 10, Batch: 180, Loss: 0.0578\n",
            "Epoch: 10, Batch: 190, Loss: 0.0482\n",
            "Epoch: 10, Batch: 200, Loss: 0.0531\n",
            "Epoch: 10, Batch: 210, Loss: 0.0438\n",
            "Epoch: 10, Batch: 220, Loss: 0.0388\n",
            "Epoch: 10, Batch: 230, Loss: 0.0421\n",
            "Epoch: 10, Batch: 240, Loss: 0.0438\n",
            "Epoch: 10, Batch: 250, Loss: 0.0574\n",
            "Epoch: 10, Batch: 260, Loss: 0.0480\n",
            "Epoch: 10, Batch: 270, Loss: 0.0455\n",
            "Epoch: 10, Batch: 280, Loss: 0.0482\n",
            "Epoch: 10, Batch: 290, Loss: 0.0432\n",
            "Epoch: 10, Batch: 300, Loss: 0.0454\n",
            "Epoch: 10, Batch: 310, Loss: 0.0378\n",
            "Epoch: 10, Batch: 320, Loss: 0.0410\n",
            "Epoch: 10, Batch: 330, Loss: 0.0500\n",
            "Epoch: 10, Batch: 340, Loss: 0.0388\n",
            "Epoch: 10, Batch: 350, Loss: 0.0371\n",
            "Epoch: 10, Batch: 360, Loss: 0.0525\n",
            "Epoch: 10, Batch: 370, Loss: 0.0548\n",
            "Epoch: 10, Batch: 380, Loss: 0.0382\n",
            "Epoch: 10, Batch: 390, Loss: 0.0391\n",
            "Epoch: 10, Batch: 400, Loss: 0.0431\n",
            "Epoch: 10, Batch: 410, Loss: 0.0504\n",
            "Epoch: 10, Batch: 420, Loss: 0.0351\n",
            "Epoch: 10, Batch: 430, Loss: 0.0395\n",
            "Epoch: 10, Batch: 440, Loss: 0.0420\n",
            "Epoch: 10, Batch: 450, Loss: 0.0538\n",
            "Epoch: 10, Batch: 460, Loss: 0.0442\n",
            "Epoch: 10, Batch: 470, Loss: 0.0469\n",
            "Epoch: 10, Batch: 480, Loss: 0.0425\n",
            "Epoch: 10, Batch: 490, Loss: 0.0374\n",
            "Epoch: 10, Batch: 500, Loss: 0.0406\n",
            "Epoch: 10, Batch: 510, Loss: 0.0438\n",
            "Epoch: 10, Batch: 520, Loss: 0.0582\n",
            "Epoch: 10, Batch: 530, Loss: 0.0488\n",
            "Epoch: 10, Batch: 540, Loss: 0.0393\n",
            "Epoch: 10, Batch: 550, Loss: 0.0428\n",
            "Epoch: 10, Batch: 560, Loss: 0.0553\n",
            "Epoch: 10, Batch: 570, Loss: 0.0448\n",
            "Epoch: 10, Batch: 580, Loss: 0.0465\n",
            "Epoch: 10, Batch: 590, Loss: 0.0434\n",
            "Epoch: 10, Batch: 600, Loss: 0.0330\n",
            "Epoch: 10, Batch: 610, Loss: 0.0495\n",
            "Epoch: 10, Batch: 620, Loss: 0.0455\n",
            "Epoch: 10, Batch: 630, Loss: 0.0555\n",
            "Epoch: 10, Batch: 640, Loss: 0.0437\n",
            "Epoch: 10, Batch: 650, Loss: 0.0384\n",
            "Epoch: 10, Batch: 660, Loss: 0.0515\n",
            "Epoch: 10, Batch: 670, Loss: 0.0362\n",
            "Epoch: 10, Batch: 680, Loss: 0.0530\n",
            "Epoch: 10, Batch: 690, Loss: 0.0407\n",
            "Epoch: 10, Batch: 700, Loss: 0.0478\n",
            "Epoch: 10, Batch: 710, Loss: 0.0441\n",
            "Epoch: 10, Batch: 720, Loss: 0.0661\n",
            "Epoch: 10, Batch: 730, Loss: 0.0538\n",
            "Epoch: 10, Batch: 740, Loss: 0.0473\n",
            "Epoch: 10, Batch: 750, Loss: 0.0492\n",
            "Epoch: 10, Batch: 760, Loss: 0.0538\n",
            "Epoch: 10, Batch: 770, Loss: 0.0373\n",
            "Epoch: 10, Batch: 780, Loss: 0.0418\n",
            "Epoch: 10, Batch: 790, Loss: 0.0391\n",
            "Epoch: 10, Batch: 800, Loss: 0.0394\n",
            "Epoch: 10, Batch: 810, Loss: 0.0394\n",
            "Epoch: 10, Batch: 820, Loss: 0.0401\n",
            "Epoch: 10, Batch: 830, Loss: 0.0380\n",
            "Epoch: 10, Batch: 840, Loss: 0.0359\n",
            "Epoch: 10, Batch: 850, Loss: 0.0529\n",
            "Epoch: 10, Batch: 860, Loss: 0.0509\n",
            "Epoch: 10, Batch: 870, Loss: 0.0599\n",
            "Epoch: 10, Batch: 880, Loss: 0.0469\n",
            "Epoch: 10, Batch: 890, Loss: 0.0579\n",
            "Epoch: 10, Batch: 900, Loss: 0.0448\n",
            "Epoch: 10, Batch: 910, Loss: 0.0457\n",
            "Epoch: 10, Batch: 920, Loss: 0.0567\n",
            "Epoch: 10, Batch: 930, Loss: 0.0424\n",
            "Epoch: 10, Batch: 940, Loss: 0.0425\n",
            "Epoch: 10, Batch: 950, Loss: 0.0432\n",
            "Epoch: 10, Batch: 960, Loss: 0.0466\n",
            "Epoch: 10, Batch: 970, Loss: 0.0539\n",
            "Epoch: 10, Batch: 980, Loss: 0.0538\n",
            "Epoch: 10, Batch: 990, Loss: 0.0421\n",
            "Epoch: 10, Batch: 1000, Loss: 0.0496\n",
            "Epoch: 10, Batch: 1010, Loss: 0.0440\n",
            "Epoch: 10, Batch: 1020, Loss: 0.0530\n",
            "Epoch: 10, Batch: 1030, Loss: 0.0487\n",
            "Epoch: 10, Batch: 1040, Loss: 0.0448\n",
            "Epoch: 10, Batch: 1050, Loss: 0.0466\n",
            "Epoch: 10, Batch: 1060, Loss: 0.0590\n",
            "Epoch: 10, Batch: 1070, Loss: 0.0404\n",
            "Epoch: 10, Batch: 1080, Loss: 0.0538\n",
            "Epoch: 10, Batch: 1090, Loss: 0.0700\n",
            "Epoch: 10, Batch: 1100, Loss: 0.0438\n",
            "Epoch: 10, Batch: 1110, Loss: 0.0431\n",
            "Epoch: 10, Batch: 1120, Loss: 0.0498\n",
            "Epoch: 10, Batch: 1130, Loss: 0.0557\n",
            "Epoch: 10, Batch: 1140, Loss: 0.0497\n",
            "Epoch: 10, Batch: 1150, Loss: 0.0483\n",
            "Epoch: 10, Batch: 1160, Loss: 0.0577\n",
            "Epoch: 10, Batch: 1170, Loss: 0.0310\n",
            "Epoch: 10, Batch: 1180, Loss: 0.0540\n",
            "Epoch: 10, Batch: 1190, Loss: 0.0509\n",
            "Epoch: 10, Batch: 1200, Loss: 0.0500\n",
            "Epoch: 10, Batch: 1210, Loss: 0.0460\n",
            "Epoch: 10, Batch: 1220, Loss: 0.0390\n",
            "Epoch: 10, Batch: 1230, Loss: 0.0351\n",
            "Epoch: 10, Batch: 1240, Loss: 0.0554\n",
            "Epoch: 10, Batch: 1250, Loss: 0.0440\n",
            "Epoch: 10, Batch: 1260, Loss: 0.0347\n",
            "Epoch: 10, Batch: 1270, Loss: 0.0465\n",
            "Epoch: 10, Batch: 1280, Loss: 0.0489\n",
            "Epoch: 10, Batch: 1290, Loss: 0.0455\n",
            "Epoch: 10, Batch: 1300, Loss: 0.0350\n",
            "Epoch: 10, Batch: 1310, Loss: 0.0519\n",
            "Epoch: 10, Batch: 1320, Loss: 0.0494\n",
            "Epoch: 10, Batch: 1330, Loss: 0.0416\n",
            "Epoch: 10, Batch: 1340, Loss: 0.0430\n",
            "Epoch: 10, Batch: 1350, Loss: 0.0557\n",
            "Epoch: 10, Batch: 1360, Loss: 0.0423\n",
            "Epoch: 10, Batch: 1370, Loss: 0.0387\n",
            "Epoch: 10, Batch: 1380, Loss: 0.0421\n",
            "Epoch: 10, Batch: 1390, Loss: 0.0597\n",
            "Epoch: 10, Batch: 1400, Loss: 0.0437\n",
            "Epoch: 10, Batch: 1410, Loss: 0.0407\n",
            "Epoch: 10, Batch: 1420, Loss: 0.0366\n",
            "Epoch: 10, Batch: 1430, Loss: 0.0506\n",
            "Epoch: 10, Batch: 1440, Loss: 0.0464\n",
            "Epoch: 10, Batch: 1450, Loss: 0.0504\n",
            "Epoch: 10, Train Loss: 0.0467, Val Loss: 0.0525\n",
            "Input: gfbs, Decrypted: FELL\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import copy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "# Data Preparation\n",
        "def load_data(file_path):\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Filter rows where 'Output' length is <=500\n",
        "    df = df[df['output'].str.len() <= 200]\n",
        "\n",
        "    # Get the count of such rows\n",
        "    count_filtered = len(df)\n",
        "\n",
        "    # Randomly select 250,000 rows (if available)\n",
        "    if count_filtered > 400000:\n",
        "        df = df.sample(n=400000, random_state=42)\n",
        "    print(len(df))\n",
        "    inputs = df['input'].astype(str).tolist()\n",
        "    outputs = df['output'].astype(str).tolist()\n",
        "\n",
        "\n",
        "    return inputs, outputs\n",
        "\n",
        "# Tokenization and Vocabulary\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.char2idx = {}\n",
        "        self.idx2char = {}\n",
        "        self.pad_token = 0\n",
        "        self.sos_token = 1\n",
        "        self.eos_token = 2\n",
        "        self.unk_token = 3\n",
        "        self._build_vocab()\n",
        "\n",
        "    def _build_vocab(self):\n",
        "        # Special tokens\n",
        "        special_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
        "        # All printable characters\n",
        "        all_chars = list(string.printable)\n",
        "\n",
        "        # Create vocabulary\n",
        "        self.char2idx = {token: idx for idx, token in enumerate(special_tokens)}\n",
        "        self.char2idx.update({char: idx+len(special_tokens) for idx, char in enumerate(all_chars)})\n",
        "\n",
        "        # Reverse mapping\n",
        "        self.idx2char = {idx: char for char, idx in self.char2idx.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.char2idx)\n",
        "\n",
        "    def encode(self, text):\n",
        "        return [self.char2idx.get(char, self.unk_token) for char in text]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        return ''.join([self.idx2char.get(idx, '<UNK>') for idx in indices if idx not in {self.pad_token, self.sos_token, self.eos_token}])\n",
        "\n",
        "# Dataset Class\n",
        "class CipherDataset(data.Dataset):\n",
        "    def __init__(self, inputs, outputs, vocab, max_length):\n",
        "        self.inputs = inputs\n",
        "        self.outputs = outputs\n",
        "        self.vocab = vocab\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.inputs[idx]\n",
        "        output_text = self.outputs[idx]\n",
        "\n",
        "        # Encode with SOS and EOS tokens\n",
        "        input_encoded = [self.vocab.sos_token] + self.vocab.encode(input_text) + [self.vocab.eos_token]\n",
        "        output_encoded = [self.vocab.sos_token] + self.vocab.encode(output_text) + [self.vocab.eos_token]\n",
        "\n",
        "        # Pad sequences\n",
        "        input_padded = input_encoded + [self.vocab.pad_token] * (self.max_length - len(input_encoded))\n",
        "        output_padded = output_encoded + [self.vocab.pad_token] * (self.max_length - len(output_encoded))\n",
        "\n",
        "        # Truncate if necessary\n",
        "        input_padded = input_padded[:self.max_length]\n",
        "        output_padded = output_padded[:self.max_length]\n",
        "\n",
        "        return torch.tensor(input_padded), torch.tensor(output_padded)\n",
        "\n",
        "# Transformer Model (same as your implementation)\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        # Q, K, V shapes: (batch_size, num_heads, seq_len, d_k)\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attn_probs = torch.softmax(scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        # Source mask\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # (batch_size, 1, 1, src_len)\n",
        "\n",
        "        # Target mask\n",
        "        tgt_pad_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)  # (batch_size, 1, 1, tgt_len)\n",
        "        tgt_len = tgt.size(1)\n",
        "        tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()\n",
        "        tgt_mask = tgt_pad_mask & tgt_sub_mask  # (batch_size, 1, tgt_len, tgt_len)\n",
        "\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        output = self.fc(dec_output)\n",
        "        return output\n",
        "\n",
        "# Training Function\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    model.train()\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch_idx, (src, tgt) in enumerate(train_loader):\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt[:, :-1])\n",
        "\n",
        "            loss = criterion(output.contiguous().view(-1, len(vocab)),\n",
        "                           tgt[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f'Epoch: {epoch+1}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        val_loss = evaluate_model(model, val_loader, criterion, device)\n",
        "        print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/vigenere_vanilla_100.pth')\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in data_loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            loss = criterion(output.contiguous().view(-1, len(vocab)),\n",
        "                           tgt[:, 1:].contiguous().view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Inference Function\n",
        "def decrypt_text(model, text, vocab, max_length, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Encode the input text\n",
        "        encoded = [vocab.sos_token] + vocab.encode(text) + [vocab.eos_token]\n",
        "        encoded = encoded + [vocab.pad_token] * (max_length - len(encoded))\n",
        "        encoded = torch.tensor(encoded[:max_length]).unsqueeze(0).to(device)\n",
        "\n",
        "        # Initialize target with SOS token\n",
        "        target = torch.tensor([[vocab.sos_token]]).to(device)\n",
        "\n",
        "        for _ in range(max_length - 1):\n",
        "            output = model(encoded, target)\n",
        "            next_token = output.argmax(2)[:, -1].item()\n",
        "            if next_token == vocab.eos_token:\n",
        "                break\n",
        "            target = torch.cat([target, torch.tensor([[next_token]]).to(device)], dim=1)\n",
        "\n",
        "        # Decode the output\n",
        "        decrypted = vocab.decode(target[0].cpu().numpy())\n",
        "        return decrypted\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and prepare data\n",
        "    inputs, outputs = load_data('/content/Full_training_vigenere_100.xlsx')\n",
        "\n",
        "    # Create vocabulary\n",
        "    vocab = Vocabulary()\n",
        "\n",
        "    # Split data into train and validation\n",
        "    train_inputs, val_inputs, train_outputs, val_outputs = train_test_split(\n",
        "        inputs, outputs, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    max_length = 256  # Adjust based on your data\n",
        "    train_dataset = CipherDataset(train_inputs, train_outputs, vocab, max_length)\n",
        "    val_dataset = CipherDataset(val_inputs, val_outputs, vocab, max_length)\n",
        "\n",
        "    # Create data loaders\n",
        "    batch_size = 220\n",
        "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = Transformer(\n",
        "        src_vocab_size=len(vocab),\n",
        "        tgt_vocab_size=len(vocab),\n",
        "        d_model=512,\n",
        "        num_heads=8,\n",
        "        num_layers=8,\n",
        "        d_ff=1024,\n",
        "        max_seq_length=max_length,\n",
        "        dropout=0.1018942343827998\n",
        "    ).to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=vocab.pad_token)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.00011040693316443509, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 10\n",
        "    trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
        "\n",
        "    # Test the model\n",
        "    test_text = \"gfbs\"  # Should decrypt to \"fear\"\n",
        "    decrypted = decrypt_text(trained_model, test_text, vocab, max_length, device)\n",
        "    print(f\"Input: {test_text}, Decrypted: {decrypted}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxOd_EC5aWJ9",
        "outputId": "a40f0672-79be-4864-d5b6-65f8b1ea8d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}